no-interrupt:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  interruptible: False
  script:
    - echo "This pipeline is not interruptible"

after-script-test:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      changes:
        - "gitlab-ci/src/after_script/*"
        - "gitlab-ci/config/*"
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
  needs: [] # don't wait on other jobs
  script:
    - |
      set -eExuo pipefail

      cd "${CI_PROJECT_DIR}"

      shellcheck -x gitlab-ci/src/after_script/*.sh

      buildevents cmd "$CI_PIPELINE_ID" "$CI_JOB_ID" "$CI_JOB_NAME" -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

bazel-build-fuzzers:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=fuzzing --build_tag_filters=libfuzzer"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-build-fuzzers-afl:
  extends:
    - .bazel-test-all
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=afl"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

# check if this one works
bazel-build-fuzzers-weekly:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-fuzzers-to-clusterfuzz"'
  needs: [] # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      gcloud auth activate-service-account --key-file "${FUZZING_GCP_SERVICE_KEY}"
      ./build-all-fuzzers.sh --zip
      cd fuzzer_build
      gsutil -m cp libfuzzer_asan_linux_*.zip gs://ic_fuzzer_builds
      gsutil -m cp afl_asan_linux_*.zip gs://ic_fuzzer_builds

bazel-build-fuzzers-archives:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - bin/build-all-fuzzers.sh
        - bazel/fuzz_testing.bzl
  needs: [] # don't wait on other jobs
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      ./build-all-fuzzers.sh --zip

.bazel-test-all:
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  tags:
    - dfinity-ic
    - bazel
  artifacts:
    when: always
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit: bazel-testlogs-gitlab/**/test.xml
  variables:
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
    BAZEL_COMMAND: "test"
    BAZEL_TARGETS: "//..."
  script:
    - ./gitlab-ci/src/bazel-ci/main.sh
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - !reference [after_script]

bazel-test-coverage:
  extends:
    - .bazel-test-all
    - .rules-post-master
  timeout: 80 minutes
  artifacts:
    expire_in: 14 days
    when: always
    paths:
      - cov_targets.txt
      - cov_report.dat
      - cov_html
  variables:
    BAZEL_COMMAND: "coverage"
    BAZEL_EXTRA_ARGS: "--combined_report=lcov"
  script:
    - |
      bazel query --universe_scope=//... \
          "kind(test, //rs/...) except kind(test, allrdeps(attr('tags', 'canister', //rs/...)))" > cov_targets.txt
      # shellcheck disable=SC2046,SC2086
      bazel ${BAZEL_STARTUP_ARGS} coverage ${BAZEL_CI_CONFIG} ${BAZEL_EXTRA_ARGS} --test_timeout=3000 \
          --combined_report=lcov $(<cov_targets.txt) || true
      cp bazel-out/_coverage/_coverage_report.dat cov_report.dat
      genhtml --output cov_html cov_report.dat
  after_script:
    - bazel clean --expunge

bazel-test-all:
  artifacts:
    when: always
    paths:
      - bazel-build-log*.json.gz
      - bazel-bep.pb
      - bazel-targets
    reports:
      junit: bazel-testlogs-gitlab/**/test.xml
  extends:
    - .bazel-test-all
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going $BAZEL_EXTRA_ARGS_RULES"
    RUN_ON_DIFF_ONLY: "true" # only test targets that changed
  timeout: 80 minutes

bazel-system-tests-k8s:
  extends:
    - .bazel-test-all
  tags:
    - dfinity-ic
    - sf
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      when: manual
      allow_failure: true
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
      allow_failure: true
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "system-tests-k8s-nightly"
  variables:
    RUST_LOG: info
    KUBECONFIG: "$KUBECONFIG_TNET_CREATOR"
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel $BAZEL_EXTRA_ARGS_RULES --jobs=7 --test_tag_filters=k8s,-manual --k8s"
  timeout: 150 minutes

bazel-system-test-hourly:
  extends:
    - .bazel-test-all
    - .rules-post-master
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_hourly"
  timeout: 120 minutes

bazel-system-test-hotfix:
  extends:
    - .bazel-test-all
  #  If on the RC branch, whether "hotfix" is in the commit message or not,
  #  always perform automatic execution of the prod hotfix tests. This means that, hotfix
  #  tests are not only exercised on hotfix pipelines, but are also exercised on nightly
  #  release qualification pipelines to ensure the hotfix tests are always working.
  rules:
    - if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
      when: always
    - if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "trigger"
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_MERGE_REQUEST_TITLE =~ /(\[rc\]|hotfix)/i'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_hotfix"

bazel-system-test-staging:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_staging"
  allow_failure: true

bazel-system-test-nightly:
  extends:
    - .bazel-test-all
    - .rules-rollout-pipeline-auto
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly"
  timeout: 7h 30m

bazel-system-test-nightly-nns:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "nns-nightly"'
  variables:
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly_nns"
  timeout: 60 minutes

bazel-config-check-all-rebuild:
  extends:
    - .bazel-test-all
  rules:
    - if: $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
    - !reference [.rules-master-pipeline-no-merge-train-rust-bazel-changed, rules]
  variables:
    BAZEL_EXTRA_ARGS: "--keep_going --config=check"
    BAZEL_COMMAND: "build"
    BAZEL_TARGETS: "//rs/..."

bazel-test-all-rebuild:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"'
      when: manual
      allow_failure: true
    - if: '$SCHEDULE_NAME == "run-all-master"'
      when: manual
      allow_failure: true
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_CI_CONFIG: "--config=ci"
    BAZEL_COMMAND: "build"
    BAZEL_EXTRA_ARGS: "--repository_cache= --disk_cache= --noremote_accept_cached --remote_instance_name=${CI_COMMIT_SHA} --@rules_rust//rust/settings:pipelined_compilation=True"
  timeout: 2h

bazel-test-macos:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i'
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - !reference [.rules-master-pipeline-no-merge-train-rust-bazel-changed, rules]
  tags:
    - macos
  variables:
    BAZEL_STARTUP_ARGS: "--output_base /var/tmp/bazel-output//${CI_CONCURRENT_ID}"
    BAZEL_CI_CONFIG: "--config=ci --config macos_ci"
    BAZEL_COMMAND: "test"
    BAZEL_EXTRA_ARGS: "--test_tag_filters=test_macos"
    BAZEL_TARGETS: "//rs/... //publish/binaries/..."
  timeout: 90 minutes

.build-ic:
  needs: []
  artifacts:
    reports:
      dotenv: nns.release.env
    paths:
      - bazel-build-log*.json*
      - build-ic.tar
  script:
    - gitlab-ci/src/ci-scripts/build-ic.sh

# MR Pipeline
build-ic:
  extends:
    - .build-ic
    - .rules-master-pipeline-no-merge-train
  variables:
    # only build binaries, canisters, ic-os if there are changes
    RUN_ON_DIFF_ONLY: "true"
    BAZEL_COMMAND: "build"

lock-generate:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/config/main.yml
        - ".bazelrc"
        - ".bazelversion"
        - "**/*.bazel"
        - "**/*.bzl"
        - "**/*.lock"
        - "**/*.rs"
        - "**/*.toml"
  needs: []
  tags:
    - dfinity-ic
    - bazel
  script:
    - ./gitlab-ci/src/ci-scripts/lock-generate.sh

pre-commit:
  variables:
    # Set the pre-commit home to this directory so we can cache it
    # more easily.
    PRE_COMMIT_HOME: /cache/pre-commit/$CI_CONCURRENT_ID
  extends:
    - .rules-master-pipeline-and-merge-request
  needs: [] # don't wait on other jobs
  tags:
    - dfinity-ic
    - bazel
  script:
    - ./gitlab-ci/src/ci-scripts/pre-commit.sh

python-ci-tests:
  rules:
    # this job breaks when not run against the default branch
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"'
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/'
  needs: []
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
  artifacts:
    reports:
      junit: test_report.xml
    paths:
      - gitlab-ci/src/htmlcov
  script:
    - |
      set -xeuo pipefail
      pip3 install --ignore-installed -r requirements.txt
      cd gitlab-ci/src
      pytest --ignore=gitlab_config/ -v -o junit_family=xunit1 --junitxml=../../test_report.xml --cov=. --cov-report=term --cov-report=term-missing --cov-report=html --cov-branch

cargo-clippy-linux:
  needs: [] # don't wait on other jobs
  extends:
    - .rules-master-pipeline-and-merge-request-rust-changed
  variables:
    CARGO_BUILD_TARGET: "x86_64-unknown-linux-gnu"
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- \
          "$CI_PROJECT_DIR"/gitlab-ci/src/ci-scripts/rust-lint.sh

cargo-build-release-linux:
  needs: [] # don't wait on other jobs
  extends:
    - .rules-master-pipeline-and-merge-request-rust-changed
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- cargo build --release

benchmarks:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "rust-benchmarks"'
  needs: []
  artifacts:
    paths:
      - report
  timeout: 12h
  variables:
    BAZEL_COMMAND: "run"
    RUST_BACKTRACE: "full"
  tags:
    - rust-benchmarks
  script:
    - ./gitlab-ci/src/ci-scripts/rust-benchmarks.sh
  parallel:
    matrix:
      - TARGETS: "//rs/crypto/..."
      - TARGETS: "//rs/certification/..."
      - TARGETS: "//rs/state_manager/..."
      - TARGETS: "//rs/boundary_node/ic_boundary/..."
      # IDX-2849
      #- TARGETS: "//rs/execution_environment/..."
      # IDX-2850
      #- TARGETS: "//... - //rs/crypto/... - //rs/execution_environment/..."

build-determinism:
  extends:
    - .rules-master-pipeline-no-merge-train
  needs:
    - job: bazel-test-all
      artifacts: true
    - job: build-ic
      artifacts: true
  parallel:
    matrix:
      - TARGET: "//publish/binaries:upload"
        PATH0: "release"
        PATH1: "build-ic/release"
      - TARGET: "//publish/canisters:upload"
        PATH0: "canisters"
        PATH1: "build-ic/canisters"
      - TARGET: "//ic-os/guestos/envs/prod:upload_update-img"
        PATH0: "guest-os/update-img"
        PATH1: "build-ic/icos/guestos"
      - TARGET: "//ic-os/hostos/envs/prod:upload_update-img"
        PATH0: "host-os/update-img"
        PATH1: "build-ic/icos/hostos"
      - TARGET: "//ic-os/setupos/envs/prod:upload_disk-img"
        PATH0: "setup-os/disk-img"
        PATH1: "build-ic/icos/setupos"
        DISKIMG: "true"
  script:
    - gitlab-ci/src/ci-scripts/build-determinism.sh

cut-release-candidate:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "release-candidate-cut"'
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      # The remote might already exist from a previous CI job run because GitLab re-uses the git repo.
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      RC_BRANCH_NAME="rc--$(date '+%Y-%m-%d_%H-%M')"
      git switch --force-create "$RC_BRANCH_NAME" HEAD
      git push --force --set-upstream origin  "$RC_BRANCH_NAME"

# The actual logic for Honeycomb metrics export happens in the after script of these jobs.
# We export the Honeycomb API metrics in the after script, not in the job script. Because `buildevents build`
# must be run after `buildevents step` of the common after script.

notify-gitlab-success:
  rules:
    # Run on schedule pipelines as several Honeycomb alert rules rely on this.
    # TODO(IDX-2856): Disable when alerts will be send from superset.
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
      when: on_success
    # Send a slack notification on rc--* pipeline succeeds.
    # Limit to "push" pipeline source so that GitLab doesn't send spurious alerts for manual or
    # scheduled pipelines that developers may create off the rc branch.
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
      when: on_success
  stage: finalize
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      pip3 install --ignore-installed -r requirements.txt

      # TODO(IDX-2856): remove this top level "if" when we will not need to run the job for schedule pipelines.
      if [[ "$CI_PIPELINE_SOURCE" == "push" ]] && [[ "$CI_COMMIT_REF_NAME" =~ ^rc--.* ]]; then
        if [[ "${CI_COMMIT_MESSAGE,,}" =~ hotfix ]]; then
            MESSAGE="✔ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. 🫑🫑🫑"
        else
            MESSAGE="✅ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. 🎉🎉🎉"
        fi
        cd "${CI_PROJECT_DIR}/gitlab-ci/src" || true
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" notify-slack -- notify_slack/notify_slack.py \
          "${MESSAGE}" --channel "release-management-alerts"
      fi

notify-gitlab-failure:
  rules:
    # Send a slack alert on rc--* pipeline failures.
    # Limit to "push" pipeline source so that GitLab doesn't send spurious alerts for manual or
    # scheduled pipelines that developers may create off the rc branch.
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/'
      when: on_failure
  stage: finalize
  dependencies: [] # don't copy artifacts from other jobs
  script:
    - |
      pip3 install --ignore-installed -r requirements.txt

      echo "notify gitlab failure"
      if [[ "${CI_COMMIT_MESSAGE,,}" =~ hotfix ]]; then
          MESSAGE="✘ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. 🌶🌶🌶"
      else
          MESSAGE="❌ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. 😭😭😭"
      fi
      cd "${CI_PROJECT_DIR}/gitlab-ci/src" || true
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" notify-slack -- notify_slack/notify_slack.py \
          "${MESSAGE}" --channel "release-management-alerts"

commit-lint:
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      allow_failure: true
  script:
    - ./gitlab-ci/src/ci-scripts/commit-lint.sh

zz-generated-gitlab:
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/config/**/*
        - .gitlab-ci.yml
  script:
    - |
      set -eEuo pipefail

      output_file="gitlab-ci/config/zz-generated-gitlab-ci.yaml"

      curl -G "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/ci/lint" \
          -d "dry_run=true" \
          -d "include_jobs=true" \
          -d "ref=$CI_COMMIT_REF_NAME" \
          -H "Authorization: Bearer $GITLAB_API_TOKEN" | jq -r '.merged_yaml' >"$output_file"

      yq  'sort_keys(...)' -i "$output_file"

      if [ -n "$(git status --porcelain)" ]; then
          git config --global user.email "idx@dfinity.org"
          git config --global user.name "IDX GitLab Automation"
          git commit -am "Updating $output_file"
          git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git"
          git push --set-upstream origin HEAD:"$CI_COMMIT_REF_NAME"
      else
          echo "git working tree clean - no changes to be committed"
      fi

bazel-test-bare-metal:
  extends:
    - .bazel-test-all
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "setupos-bare-metal-smoke-test"'
  tags:
    - dfinity-ic
    - bazel
    - zh
  needs: [] # don't wait on other jobs
  script:
    - |
      # shellcheck disable=SC2046,SC2086
      bazel ${BAZEL_STARTUP_ARGS} run ${BAZEL_CI_CONFIG} \
        //ic-os/setupos/envs/dev:launch_bare_metal -- \
          --config_path "$(realpath  ./ic-os/scripts/bare_metal_deployment/zh2-dll01.yaml)" \
          --csv_filename "$(realpath "$ZH2_DLL01_CSV_SECRETS_PATH")" \
          --file_share_ssh_key "$(realpath "$ZH2_FILE_SHARE_KEY_PATH")" \
          --file_share_username ci_interim \
          --ci_mode

sync-codeowners:
  needs: []
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - gitlab-ci/src/ci-scripts/sync-codeowners.sh
        - .gitlab/CODEOWNERS
  script:
    - ./gitlab-ci/src/ci-scripts/sync-codeowners.sh
