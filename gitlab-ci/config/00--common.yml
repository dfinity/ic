include:
  - local: /gitlab-ci/config/00--common--rules.yml

stages:             # Files from the given stage should be prefixed with:
  - automation          # temp
  - init                # 10--
  - test                # 20--
  - deploy              # only required for gitlab pages (job "pages" needs to be in "deploy" stage)
  - cargo-build         # 30--
  - cargo-test          # 40--
  - guest-os-build      # 46--
  - guest-os-test       # 47--
  - e2e-tests           # 50--
  - host-os-build       # 52--
  - build-determinism-test  # 53--
  - host-os-test        # 54--
  - prod-tests          # 60--
    # Shard prod tests into 5 groups, because there are 5 'cdnightly' testnet environments.
    # The stages are purely for visual convenience when rendering the pipeline in the GitLab UI.
  - prod-tests-01
  - prod-tests-02
  - prod-tests-03
  - prod-tests-04
  - prod-tests-05
  - benchmark-tests
  - benchmark-spot-tests
  - push-branches       # 75--
  - npm-release         # 80--
  - finalize            # 100--

default:
  # Retry config copied from:
  # https://gitlab.com/gitlab-org/gitlab/blob/master/.gitlab/ci/global.gitlab-ci.yml#L1-9
  # Complete description available at:
  # https://docs.gitlab.com/ee/ci/yaml/#retry
  retry:
    max: 2  # This is confusing but this means "3 runs at max".
    when:
      - unknown_failure
      - api_failure
      - runner_system_failure

variables:
  TEST_ES_HOSTNAMES: >-
    elasticsearch-node-0.testnet.dfinity.systems:443,
    elasticsearch-node-1.testnet.dfinity.systems:443,
    elasticsearch-node-2.testnet.dfinity.systems:443
  CI_PRE_CLONE_SCRIPT: |
    # This script caches the git repo on the host.

    # MacOS note: the gitlab runner will ignore this var on MacOS since config does not have
    # pre_clone_script set in the runner config

    echo -e "\e[0Ksection_start:$(date +%s):pre_clone_script[collapsed=true]\r\e[0KClick here to see the pre_clone_script"
    set -eExuo pipefail

    GIT_CACHE_PATH="/cache/git-v3/@{CI_PROJECT_PATH}/@{CI_CONCURRENT_ID}"
    mkdir -p "@{GIT_CACHE_PATH}"

    pushd "@{GIT_CACHE_PATH}"
    # Step 1. Seed the repo if it doesn't exit or has been corrupted.
    # On CI we've observed partial downloads of the repo [e.g. missing .git dir]
    if ! git fsck; then
      echo "Cloning fresh git repository"
      find . -delete
      time git clone "@{CI_REPOSITORY_URL}" .
    fi
    popd

    # Step 2. Fetch the commit sha into the cache.
    pushd "@{GIT_CACHE_PATH}"
    # CI_REPOSITORY_URL contains the CI_JOB_TOKEN.
    # The cached one will have come from a previous job, and thus its token
    # is invalid. So just update the token.
    git remote set-url origin "@{CI_REPOSITORY_URL}"

    # Fetch the target commit sha into the cache.
    # If this fails, for example if the repo has become corrupted, then wipe
    # the cache and perform a fresh clone.
    if ! time git fetch origin "@{CI_COMMIT_SHA}"; then
      echo "Git fetch into local cached failed. Making a clean git clone"
      find "@{GIT_CACHE_PATH}" -mindepth 1 -delete
      time git clone "@{CI_REPOSITORY_URL}" .
    fi
    popd

    # Step 3. Clone a fresh working repo from the cache.
 
    # This directory should not exist unless something changed on GitLab,
    # or someone has bind mounted it from the runner. To be safe just delete it.
    rm -fr "@{CI_PROJECT_DIR}"
    mkdir -p "@{CI_PROJECT_DIR}"

    pushd "@{CI_PROJECT_DIR}"
    time git clone "@{GIT_CACHE_PATH}" .
    git checkout "@{CI_COMMIT_SHA}"
    git remote set-url origin "@{CI_REPOSITORY_URL}"
    popd

before_script:
  - |
    # Execute the before_script section
    echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"  # first close before_script section, if open

    # Start the (collapsed) before_script section
    set -eExuo pipefail
    echo -e "\e[0Ksection_start:$(date +%s):before_script[collapsed=true]\r\e[0KClick here to see the before_script section"

    date +%s > "/tmp/job_start_date_${CI_JOB_ID:-}"
    # date -Iseconds is not supported by BSD date (macOS)
    date +"%Y-%m-%dT%H:%M:%S%z" > "/tmp/job_start_iso_date_${CI_JOB_ID:-}"
    date
    command -v ssh-agent > /dev/null
    test -z "${SSH_AUTH_SOCK:-}" && { eval "$(ssh-agent -s)"; ssh-add - <<< "${SSH_PRIVATE_KEY}"; }
    mkdir -p ~/.ssh
    chmod 0700 ~/.ssh

    echo -e "Host *\nUser gitlab-runner\n" > ~/.ssh/config
    ulimit -n 8192
    date

    export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}

    if [ "${CI_DISPOSABLE_ENVIRONMENT:-false}" != "true" ]; then
      # MacOS + shell builds
      export CARGO_TARGET_DIR="$CI_PROJECT_DIR/target"
    else
    # GitLab may not preserve some file permissions that are chowned in the pre clone script.
    # And the files will all be owned by root.
    # Some commands care about the permissions of the configs they use. For example, Ansible will refuse
    # to use a cfg file that a different user owns.
      sudo chown ubuntu:ubuntu -R "${CI_PROJECT_DIR}"
      sudo find "${CI_PROJECT_DIR}" -type d -exec chmod 0755 '{}' \;
    fi

    # Make sure Capsule writes to the correct Honeycomb dataset.
    CAPSULE_ID="$(echo "${CI_JOB_NAME}" | tr ' ' '-')"
    export CAPSULE_ID
    CAPSULE_EXTRA_ARGS="${CAPSULE_EXTRA_ARGS:-}"
    export CAPSULE_ARGS="${CAPSULE_EXTRA_ARGS} -c '${CAPSULE_ID}' -j '${CI_JOB_URL}' -b s3 --honeycomb_dataset='${CAPSULE_HONEYCOMB_DATASET}' --honeycomb_token='${CAPSULE_HONEYCOMB_TOKEN}' --honeycomb_trace_id='${ROOT_PIPELINE_ID}' --honeycomb_kv=branch='${CI_COMMIT_BRANCH:-}' -t '${CI_JOB_IMAGE:-docker}'"
  - echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"


# TESTING NOTE:
# $SHELL_WRAPPER allows us to emulate CI runs without actually executing the complicated and
#                time-consuming operations.
#                In normal execution, "$SHELL_WRAPPER" will be substituted with "/usr/bin/time"
#                In CI validation, "$SHELL_WRAPPER" will be substituted with "echo"

after_script:
  - |
    # Start the after_script section
    echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

    # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
    export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
    buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

    # Finish and collapse the after_script section
    echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"

.nix-build-env-base:
  extends: .cargo-rules
  # Generally only the last push to a branch matters and older jobs can be cancelled
  # https://docs.gitlab.com/ee/ci/yaml/#interruptible
  # Jobs can override this by setting `interruptible: false`
  interruptible: true
  artifacts:
    paths:
      - "junit_data/*"
      - "coredumps/*.txt"
      - "coredumps/*.gz"
    when: always
  variables:
    GET_SOURCES_ATTEMPTS: 5
    GIT_DEPTH: 0  # Pull the complete repo initially
    GIT_STRATEGY: "fetch"  # And then pull only new commits
    # Disable cargo incremental - it's incompatible with sccache.
    CARGO_INCREMENTAL: "0"
    CARGO_BUILD_INCREMENTAL: "false"
    SCCACHE_CACHE_SIZE: "500G"
    # The default sccache idle timeout is 600, which is too short and leads to intermittent build errors.
    # https://github.com/mozilla/sccache/issues/256
    SCCACHE_IDLE_TIMEOUT: "7200"
    SCCACHE_STARTUP_TIMEOUT_MS: "30000"
    BUILD_COMMAND_PRE: ""
    BUILD_COMMAND: "echo Replace this with a build command"
    BUILD_COMMAND_POST: ""
    SHELL_WRAPPER: "/usr/bin/time"
  script:
    - |
      set -eExuo pipefail
      cd "${CI_PROJECT_DIR}/rs"

      bash -c "$BUILD_COMMAND_PRE"

      # failures will contain a counter of failed commands
      # this way nix-shell will exit with non-zero value if any of the commands fails in it
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" nix-shell -- \
      "$SHELL_WRAPPER" nix-shell --run "
        set -eExuo pipefail

        buildevents cmd \"$ROOT_PIPELINE_ID\" \"$CI_JOB_ID\" build-command -- \
        bash -c \"set -eExuo pipefail; $BUILD_COMMAND\"

        echo \"$BUILD_COMMAND_POST\"
        bash -c \"$BUILD_COMMAND_POST\"
        set +x
      "

      set +x
      echo -e "\e[0Ksection_start:$(date +%s):sccache_stats[collapsed=true]\r\e[0KClick here to see the sccache stats"
      # If the build artifacts came from the capsules cache, then sccache server will have never started.
      # Therefore mark the output advisory so it doesn't fail the job.
      "$RUSTC_WRAPPER" --show-stats || true
      echo -e "\e[0Ksection_end:$(date +%s):sccache_stats\r\e[0K"

.ubuntu-nix-docker:
  extends: .nix-build-env-base
  # Here is how docker builds work:
  # - The $CI_COMMIT_SHA is checked out at: /builds/dfinity/ic
  # - The repo is built with $BUILD_COMMAND
  # - Build results are stored in non-persisted /cargo_target
  # - The container is destroyed and all non-persisted data is dropped, including /cargo_target
  image:
    name: "registry.gitlab.com/dfinity-lab/core/docker/ic-build-nix:2022-04-20-74ee01d22-f957680f6e0d9ab5405f378ea9ad850e00e9b6d9"
  tags:
    # Build on runners that have following tags
    - dfinity
    - docker
    - ubuntu
  variables:
    SCCACHE_DIR: /cache/sccache
    RUSTC_WRAPPER: "/usr/bin/sccache-run"
    # This MUST match the directory used in our `docker-build-ic` script
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"

.ubuntu-nix-docker-pinned-dc:
  extends: .ubuntu-nix-docker
  tags:
    # We override tags to add $SELECTED_DC so we can pin jobs to one DC
    - dfinity
    - docker
    - ubuntu
    - $SELECTED_DC

.macos-nix-native:
  extends:
     - .nix-build-env-base
  tags:
    - dfinity
    - macos
  variables:
    RUSTC_WRAPPER: "/usr/local/bin/sccache"
