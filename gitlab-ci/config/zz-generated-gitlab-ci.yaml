---
".bazel-test-all":
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit: bazel-testlogs-gitlab/**/test.xml
    when: always
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
".benchmark-spot-test":
  artifacts:
    paths:
      - "$CI_JOB_STAGE/$CI_JOB_NAME"
    when: always
  dependencies: []
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
".benchmark-test":
  artifacts:
    paths:
      - "$CI_JOB_STAGE/$CI_JOB_NAME"
    when: always
  dependencies: []
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
".build-base-image": |
  set -euo pipefail

  TAG=$(date '+%Y-%m-%d-%H%M')
  echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
  pushd "$CONTEXT"
  podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
  popd
  echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

  if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
      podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
      podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
      echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
      echo "$REF_FILE" >> "digestfile-${IMAGE}"
      rm -f digestfile
  fi
".build-base-image-job":
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".rules-build-base-images"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
".build-ic":
  artifacts:
    paths:
      - bazel-build-log*.json*
      - build-ic.tar
    reports:
      dotenv: nns.release.env
  needs: []
  script:
    - |
      set -euo pipefail
      VERSION=$(git rev-parse HEAD)

      if [[ "${CI_MERGE_REQUEST_TITLE:-}" == *"[RUN_ALL_BAZEL_TARGETS]"* ]]; then
          RUN_ON_DIFF_ONLY="false"
      fi

      if [ "$CI_JOB_NAME" == "build-ic-release" ]; then
          # read NNS release version from git tree
          NNS_RELEASE_VERSION="$(jq -r '.subnets["tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe"]' testnet/mainnet_revisions.json)"
          # we pass nss version info to build-determinism-*-release jobs
          # we put it under /tmp due to git clean -ffdx within build-ic script
          echo "NNS_RELEASE_VERSION=$NNS_RELEASE_VERSION" > /tmp/nns.release.env

          # fetch and checkout this version
          git fetch origin "$NNS_RELEASE_VERSION"
          git checkout "$NNS_RELEASE_VERSION"
          # NOTE: ic/$VERSION in S3 will have artifacts
          #       for revision $NNS_RELEASE_VERSION !!!
      fi

      if [ "$CI_COMMIT_REF_PROTECTED" == "true" ]; then
          gitlab-ci/container/build-ic.sh -i -c -b
      elif [ "${RUN_ON_DIFF_ONLY:-}" == "true" ] \
          && [ "${CI_PIPELINE_SOURCE:-}" == "merge_request_event" ] \
          && [ "${CI_MERGE_REQUEST_EVENT_TYPE:-}" != "merge_train" ] \
          && [[ "${CI_MERGE_REQUEST_TARGET_BRANCH_NAME:-}" != "rc--"* ]]; then

          TARGETS=$(gitlab-ci/src/bazel-ci/diff.sh)
          ARGS=(--no-release)

          if [ "$TARGETS" == "//..." ]; then
              ARGS+=(-i -c -b)
          else
              if grep -q "ic-os" <<<"$TARGETS"; then
                  ARGS+=(-i)
              fi
              if grep -q "publish/canisters" <<<"$TARGETS"; then
                  ARGS+=(-c)
              fi
              if grep -q "publish/binaries" <<<"$TARGETS"; then
                  ARGS+=(-b)
              fi
          fi

          if [ ${#ARGS[@]} -eq 1 ]; then
              echo "No changes that require building IC-OS, binaries or canisters."
              exit 0
          fi
          gitlab-ci/container/build-ic.sh "${ARGS[@]}"
      else
          gitlab-ci/container/build-ic.sh -i -c -b --no-release
      fi

      if [ -d artifacts/icos ]; then
          # purge test image
          find ./artifacts/icos -name 'update-img-test.*' -delete
          # only keep zstd ic images
          find ./artifacts/icos -name '*.gz' -delete
      fi

      tar -cf artifacts.tar artifacts
      URL="http://$(cat /ceph-s3-info/BUCKET_HOST)/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}"
      curl --request PUT --upload-file artifacts.tar "${URL}/artifacts.tar"

      mkdir build-ic
      for DIR in release canisters icos/guestos icos/hostos icos/setupos; do
          if [ -e "artifacts/${DIR}/SHA256SUMS" ]; then
              mkdir -p "build-ic/${DIR}/"
              cp "artifacts/${DIR}/SHA256SUMS" "build-ic/${DIR}/"
          fi
      done

      EXTERNAL_URL="https://objects.$(echo "$NODE_NAME" | cut -d'-' -f1)-idx1.dfinity.network/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}/artifacts.tar"
      echo -e "Node: ${NODE_NAME:-}\nURL: ${URL}\nExternal URL: ${EXTERNAL_URL}" >./build-ic/info
      echo "${EXTERNAL_URL}" >./build-ic/url
      tar -cf build-ic.tar build-ic

      # clean up
      bazel clean --expunge

      # collect dotenv
      if [ -f /tmp/nns.release.env ]; then
          mv /tmp/nns.release.env .
      fi
".rules-build-base-images":
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
".rules-master-pipeline-and-merge-request":
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
".rules-master-pipeline-and-merge-request-rust-changed":
  rules:
    - changes:
        - "**/*.rs"
        - "**/*.toml"
        - "**/*.lock"
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
".rules-master-pipeline-no-merge-train":
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
".rules-master-pipeline-no-merge-train-rust-bazel-changed":
  rules:
    - changes:
        - ".bazelrc"
        - ".bazelversion"
        - "**/*.bazel"
        - "**/*.bzl"
        - "**/*.lock"
        - "**/*.rs"
        - "**/*.toml"
        - gitlab-ci/container/Dockerfile
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
".rules-post-master":
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      when: manual
    - if: $SCHEDULE_NAME == "run-all-master"
".rules-rollout-pipeline-auto":
  rules:
    - allow_failure: true
      if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_COMMIT_MESSAGE =~ /hotfix/i && $CI_PIPELINE_SOURCE != "trigger"
      when: manual
    - if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_PIPELINE_SOURCE != "trigger"
      when: always
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "trigger"
      when: manual
after-script-test:
  needs: []
  rules:
    - changes:
        - gitlab-ci/src/after_script/*
        - gitlab-ci/config/*
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
  script:
    - |
      set -eExuo pipefail

      cd "${CI_PROJECT_DIR}"

      shellcheck -x gitlab-ci/src/after_script/*.sh

      buildevents cmd "$CI_PIPELINE_ID" "$CI_JOB_ID" "$CI_JOB_NAME" -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh
after_script:
  - |
    # Start the after_script section
    echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

    # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
    export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
    buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

    rm -rf "${CI_PROJECT_DIR}/target"

    # Finish and collapse the after_script section
    echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
bazel-build-fuzzers:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: build
    BAZEL_EXTRA_ARGS: "--keep_going --config=fuzzing --build_tag_filters=libfuzzer"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//rs/..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-build-fuzzers-afl:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: build
    BAZEL_EXTRA_ARGS: "--keep_going --config=afl"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//rs/..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-build-fuzzers-archives:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - changes:
        - bin/build-all-fuzzers.sh
        - bazel/fuzz_testing.bzl
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      ./build-all-fuzzers.sh --zip
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-build-fuzzers-weekly:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-fuzzers-to-clusterfuzz"
  script:
    - |
      set -euo pipefail
      cd "${CI_PROJECT_DIR}"/bin
      gcloud auth activate-service-account --key-file "${FUZZING_GCP_SERVICE_KEY}"
      ./build-all-fuzzers.sh --zip
      cd fuzzer_build
      gsutil -m cp libfuzzer_asan_linux_*.zip gs://ic_fuzzer_builds
      gsutil -m cp afl_asan_linux_*.zip gs://ic_fuzzer_builds
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-config-check-all-rebuild:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
    - - changes:
          - ".bazelrc"
          - ".bazelversion"
          - "**/*.bazel"
          - "**/*.bzl"
          - "**/*.lock"
          - "**/*.rs"
          - "**/*.toml"
          - gitlab-ci/container/Dockerfile
        if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: build
    BAZEL_EXTRA_ARGS: "--keep_going --config=check"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//rs/..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-test-hotfix:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: "$CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/"
      when: always
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "trigger"
      when: manual
    - allow_failure: true
      if: "$CI_MERGE_REQUEST_TITLE =~ /(\\[rc\\]|hotfix)/i"
      when: manual
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_hotfix"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-test-hourly:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
    - ".rules-post-master"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      when: manual
    - if: $SCHEDULE_NAME == "run-all-master"
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  timeout: 120 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_hourly"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-test-nightly:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
    - ".rules-rollout-pipeline-auto"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_COMMIT_MESSAGE =~ /hotfix/i && $CI_PIPELINE_SOURCE != "trigger"
      when: manual
    - if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_PIPELINE_SOURCE != "trigger"
      when: always
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "trigger"
      when: manual
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  timeout: 7h 30m
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-test-nightly-nns:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "nns-nightly"
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  timeout: 60 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_nightly_nns"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-test-staging:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  allow_failure: true
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
    - ".rules-rollout-pipeline-auto"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_COMMIT_MESSAGE =~ /hotfix/i && $CI_PIPELINE_SOURCE != "trigger"
      when: manual
    - if: $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/ && $CI_PIPELINE_SOURCE != "trigger"
      when: always
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "trigger"
      when: manual
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=system_test_staging"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-system-tests-k8s:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      when: manual
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - sf
  timeout: 150 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--repository_cache=/cache/bazel $BAZEL_EXTRA_ARGS_RULES --jobs=5 --test_tag_filters=k8s,-manual --k8s"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    KUBECONFIG: "$KUBECONFIG_TNET_CREATOR"
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
    RUST_LOG: info
bazel-test-all:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json.gz
      - bazel-bep.pb
      - bazel-targets
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE == "merge_train"
        variables:
          BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate --flaky_test_attempts=3"
      - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i
        variables:
          BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
      - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "tnet-test"
      - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
    - if: $CI_COMMIT_REF_PROTECTED == "true" && $CI_COMMIT_TAG =~ /^release-.+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  timeout: 80 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--keep_going $BAZEL_EXTRA_ARGS_RULES"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUN_ON_DIFF_ONLY: 'true'
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-test-all-rebuild:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      when: manual
    - allow_failure: true
      if: $SCHEDULE_NAME == "run-all-master"
      when: manual
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - dfinity-ic
    - bazel
  timeout: 2h
  variables:
    BAZEL_CI_CONFIG: "--config=ci"
    BAZEL_COMMAND: build
    BAZEL_EXTRA_ARGS: "--repository_cache= --disk_cache= --noremote_accept_cached --remote_instance_name=${CI_COMMIT_SHA} --@rules_rust//rust/settings:pipelined_compilation=True"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-test-bare-metal:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "setupos-bare-metal-smoke-test"
  script:
    - |
      bazel run //ic-os/setupos/envs/dev:launch_bare_metal -- \
      --config_path "$(realpath  ./ic-os/utils/bare_metal_deployment/zh2-dll01.yaml)" \
      --csv_filename "$(realpath "$ZH2_DLL01_CSV_SECRETS_PATH")" \
      --file_share_ssh_key "$(realpath "$ZH2_FILE_SHARE_KEY_PATH")" \
      --file_share_username ci_interim \
      --ci_mode

      bazel run //ic-os/setupos/envs/prod:launch_bare_metal -- \
      --config_path "$(realpath  ./ic-os/utils/bare_metal_deployment/zh2-dll01.yaml)" \
      --csv_filename "$(realpath "$ZH2_DLL01_CSV_SECRETS_PATH")" \
      --file_share_ssh_key "$(realpath "$ZH2_FILE_SHARE_KEY_PATH")" \
      --file_share_username ci_interim \
      --ci_mode
  tags:
    - dfinity-ic
    - bazel
    - zh
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: test
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-test-coverage:
  after_script:
    - bazel clean --expunge
  artifacts:
    expire_in: 14 days
    paths:
      - cov_targets.txt
      - cov_report.dat
      - cov_html
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
    - ".rules-post-master"
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      when: manual
    - if: $SCHEDULE_NAME == "run-all-master"
  script:
    - |
      bazel query --universe_scope=//... \
          "kind(test, //rs/...) except kind(test, allrdeps(attr('tags', 'canister', //rs/...)))" > cov_targets.txt
      # shellcheck disable=SC2046,SC2086
      bazel ${BAZEL_STARTUP_ARGS} coverage ${BAZEL_CI_CONFIG} ${BAZEL_EXTRA_ARGS} \
          --combined_report=lcov $(<cov_targets.txt) || true
      cp bazel-out/_coverage/_coverage_report.dat cov_report.dat
      genhtml --output cov_html cov_report.dat
  tags:
    - dfinity-ic
    - bazel
  timeout: 80 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: coverage
    BAZEL_EXTRA_ARGS: "--combined_report=lcov"
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
bazel-test-macos:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - bazel-build-log*.json*
      - bazel-bep.pb
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TITLE =~ /\bhotfix\b/i
      variables:
        BAZEL_EXTRA_ARGS_RULES: "--test_timeout_filters=short,moderate"
    - - changes:
          - ".bazelrc"
          - ".bazelversion"
          - "**/*.bazel"
          - "**/*.bzl"
          - "**/*.lock"
          - "**/*.rs"
          - "**/*.toml"
          - gitlab-ci/container/Dockerfile
        if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
      - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - "./gitlab-ci/src/bazel-ci/main.sh"
  tags:
    - macos
  timeout: 90 minutes
  variables:
    BAZEL_CI_CONFIG: "--config=ci --config macos_ci"
    BAZEL_COMMAND: test
    BAZEL_EXTRA_ARGS: "--test_tag_filters=test_macos"
    BAZEL_STARTUP_ARGS: "--output_base /var/tmp/bazel-output//${CI_CONCURRENT_ID}"
    BAZEL_TARGETS: "//rs/... //publish/binaries/..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
before_script:
  - |
    # Execute the before_script section
    echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"  # first close before_script section, if open

    # Start the (collapsed) before_script section
    set -eExuo pipefail
    echo -e "\e[0Ksection_start:$(date +%s):before_script[collapsed=true]\r\e[0KClick here to see the before_script section"

    date +%s > "/tmp/job_start_date_${CI_JOB_ID:-}"
    # date -Iseconds is not supported by BSD date (macOS)
    date +"%Y-%m-%dT%H:%M:%S%z" > "/tmp/job_start_iso_date_${CI_JOB_ID:-}"
    date
    command -v ssh-agent > /dev/null
    test -z "${SSH_AUTH_SOCK:-}" && { eval "$(ssh-agent -s)"; ssh-add - <<< "${SSH_PRIVATE_KEY}"; }
    mkdir -p ~/.ssh
    chmod 0700 ~/.ssh

    echo -e "Host *\nUser gitlab-runner\n" > ~/.ssh/config
    date

    export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}

    if [ "${CI_DISPOSABLE_ENVIRONMENT:-false}" != "true" ]; then
      # MacOS + shell builds
      export CARGO_TARGET_DIR="$CI_PROJECT_DIR/target"
    fi

    # docker login for RO to overcome anonymous pull limit of 100 pulls / 6h
    # enterprise logged in account has 5000 pulls / 24h
    if [ "$(uname)" == "Linux" ]; then
      docker login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD_RO"
      docker-bin login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD_RO"

      # set ownership to ic-build container's user,
      # but ignore errors that happen due to git gc:
      #   `chown: changing ownership of '.git/shallow.lock': No such file or directory`
      sudo chown "$(id -u):$(id -g)" -fR "${CI_PROJECT_DIR}" || true
    fi
  - echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"
benchmark-response-payload:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER timeout 90m python3 experiments/run_large_payload_experiment.py --testnet "$TESTNET" --wg_testnet "$TESTNET" --wg_subnet 2

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
benchmark-xnet:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_xnet_experiment.py --testnet $TESTNET --hosts_ini_filename=hosts_single_node_subnets.ini

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 6 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
benchmarks:
  after_script:
    - |
      set +e # Do not fail in the after_script, try to do as much as possible instead.
      echo -e "\033[0;31m"
      echo -e "************************************************************************"
      echo -e "*** NEED BAZEL HELP? See #project-bazel and                          ***"
      echo -e "***  https://github.com/dfinity/ic/blob/master/bazel/README.md       ***"
      echo -e "*** (NEW) To regenerate Cargo Bazel lockfiles run ./bin/bazel-pin.sh ***"
      echo -e "************************************************************************"
      echo -e "\033[0m"
    - cp -R "$(realpath bazel-testlogs)" bazel-testlogs-gitlab
    - gzip bazel-build-log*.json
    - |
      echo -e "\e[0Ksection_start:$(date +%s):bazel_exporter_logs[collapsed=true]\r\e[0KClick to see Bazel exporter logs"
      bazel run //bazel/exporter:exporter --build_event_binary_file= -- -f "$(pwd)/bazel-bep.pb"
      echo -e "\e[0Ksection_end:$(date +%s):bazel_exporter_logs\r\e[0K"
    - |
      if [ "$(uname)" == "Linux" ]; then
          bazel clean --expunge
      fi
    - - |
        # Start the after_script section
        echo -e "\e[0Ksection_start:$(date +%s):after_script[collapsed=true]\r\e[0KClick here to see the after_script section. It does not affect the job success status"

        # Export all the environmental variables so that the GITLAB configured variables are available to after_script.sh
        export ROOT_PIPELINE_ID=${PARENT_PIPELINE_ID:-$CI_PIPELINE_ID}
        buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" after-script -- "${CI_PROJECT_DIR}"/gitlab-ci/src/after_script/after_script.sh

        rm -rf "${CI_PROJECT_DIR}/target"

        # Finish and collapse the after_script section
        echo -e "\e[0Ksection_end:$(date +%s):after_script\r\e[0K"
  artifacts:
    paths:
      - report
    reports:
      junit:
        - bazel-testlogs-gitlab/**/test.xml
    when: always
  extends:
    - ".bazel-test-all"
  needs: []
  parallel:
    matrix:
      - TARGETS: "//rs/crypto/..."
      - TARGETS: "//rs/state_manager/..."
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "rust-benchmarks"
  script:
    - |
      set -eEuo pipefail

      TARGET_LIST=$(bazel query "attr(tags, 'rust_bench', ${TARGETS:-'//rs/...'})")
      for TARGET in $TARGET_LIST; do
          BAZEL_TARGETS="$TARGET"
          time ./gitlab-ci/src/bazel-ci/main.sh
      done
      find -L ./bazel-out -name 'benchmark.json'

      set -x
      while IFS= read -r bench_dir; do
        echo '{}' | jq -cMr \
          --slurpfile benchmark "$bench_dir/benchmark.json" \
          --slurpfile estimates "$bench_dir/estimates.json" \
          --arg system x86_64-linux \
          --arg timestamp "$(date --utc --iso-8601=seconds)" \
          --arg rev "$CI_COMMIT_SHA" \
          '.benchmark = $benchmark[] |
          .estimates = $estimates[] |
          .package = "replica-benchmarks" |
          .system = $system |
          .timestamp = $timestamp |
          .rev = $rev |
          .revCount = 1' \
          > report.json
        curl --fail --retry 2 -sS -o /dev/null -X POST -H 'Content-Type: application/json' --data @report.json \
          "https://elasticsearch.testnet.dfinity.network/ci-performance-test/_doc"
      done < <(find -L ./bazel-out -type d -path '*/new')
  tags:
    - rust-benchmarks
  timeout: 12h
  variables:
    BAZEL_CI_CONFIG: "--config=ci --repository_cache=/cache/bazel"
    BAZEL_COMMAND: run
    BAZEL_STARTUP_ARGS: "--output_base=/var/tmp/bazel-output/"
    BAZEL_TARGETS: "//..."
    RUSTFLAGS: "--remap-path-prefix=${CI_PROJECT_DIR}=/ic"
    RUST_BACKTRACE: full
build-base-images-ref-update:
  dependencies:
    - build-guestos-base
    - build-guestos-base-dev
    - build-boundaryos-base
    - build-hostos-base
    - build-hostos-base-dev
    - build-setupos-base
    - build-setupos-base-dev
  extends:
    - ".rules-build-base-images"
  needs:
    - build-guestos-base
    - build-guestos-base-dev
    - build-boundaryos-base
    - build-hostos-base
    - build-hostos-base-dev
    - build-setupos-base
    - build-setupos-base-dev
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail
      if ! ls -1 digestfile-*; then
        echo "No digestfiles, nothing to do!"
        exit 0
      fi

      # update image ref in ref files
      for FILE in digestfile-*; do
          IMAGE="$(head -1 "$FILE")"
          REF_FILE="$(tail -1 "$FILE")"
          echo "docker.io/$IMAGE" > "$REF_FILE"
      done
      rm -f digestfile*

      # commit, push & create new merge request
      TAG=$(date '+%Y-%m-%d-%H%M')
      git remote set-url origin \
          "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git config --global user.email "idx@dfinity.org"
      git config --global user.name "IDX GitLab Automation"
      git checkout -b "base-image-refs-update-${TAG}"
      git add .
      if git diff --cached --quiet; then
          echo "No changes to commit."
          exit 0
      fi
      git commit -m "Updating container base image refs"
      git push \
          -o merge_request.create \
          -o merge_request.title="Updating container base images refs [$TAG]" \
          origin "base-image-refs-update-${TAG}" 2>&1 | tee push.info
build-boundaryos-base:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/boundary-guestos/rootfs"
    IMAGE: boundaryos-base
    REF_FILE: ic-os/boundary-guestos/rootfs/docker-base.prod
build-determinism:
  extends:
    - ".rules-master-pipeline-no-merge-train"
  needs:
    - artifacts: true
      job: bazel-test-all
    - artifacts: true
      job: build-ic
  parallel:
    matrix:
      - PATH0: release
        PATH1: build-ic/release
        TARGET: "//publish/binaries:upload"
      - PATH0: canisters
        PATH1: build-ic/canisters
        TARGET: "//publish/canisters:upload"
      - PATH0: guest-os/update-img
        PATH1: build-ic/icos/guestos
        TARGET: "//ic-os/guestos/envs/prod:upload_update-img"
      - PATH0: host-os/update-img
        PATH1: build-ic/icos/hostos
        TARGET: "//ic-os/hostos/envs/prod:upload_update-img"
      - DISKIMG: 'true'
        PATH0: setup-os/disk-img
        PATH1: build-ic/icos/setupos
        TARGET: "//ic-os/setupos/envs/prod:upload_disk-img"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -eExuo pipefail

      # bazel-targets file is expected from bazel-test-all CI job
      if [ ! -e bazel-targets ]; then
          echo "Missing 'bazel-targets' file!"
          exit 1
      fi

      if grep -q "$TARGET" bazel-targets || grep -qF "//..." bazel-targets; then
          VERSION="$(git rev-parse HEAD)"

          # build-ic.tar with SHA256SUMS files is expected from build-ic CI job
          if [ ! -e build-ic.tar ]; then
              echo "Missing 'build-ic.tar' file!"
              exit 1
          fi

          # PATH0
          mkdir -p "$PATH0"
          curl -sfS --retry 5 --retry-delay 10 \
            "https://download.dfinity.systems/ic/$VERSION/$PATH0/SHA256SUMS" \
            -o "$PATH0/SHA256SUMS"

          # PATH1
          tar -xf build-ic.tar

          # ignore *.wasm.did files
          sed -i -e '/.wasm.did/d' "$PATH0/SHA256SUMS" "$PATH1/SHA256SUMS"

          # for hostos / guestos we only care about update-img
          if [ "${DISKIMG:-}" != "true" ]; then
              sed -i -e '/disk-img/d' "$PATH0/SHA256SUMS" "$PATH1/SHA256SUMS"
          fi

          if ! diff -u "$PATH0/SHA256SUMS" "$PATH1/SHA256SUMS"; then
              set -x
              cat build-ic/info
              echo "Build Determinism Check Failed!"
              echo "Contact IDX or investigate by yourself using diffoscope:"
              echo " * [bazel-test-all]: curl -sfS https://download.dfinity.systems/ic/$VERSION/$PATH0/<artifact> -O"
              echo " * [build-ic]: curl $(cat build-ic/url) -O"
              echo "See info for pull the artifacts from both CI jobs above. Specify <artifact> based on logs (e.g. 'ic-admin.gz', 'disk-img.tar.zst')."
              echo "Note that [build-ic] artifacts.tar contains all the build artifacts (binaries, canisters and IC images)."
              set +x
              exit 1
          else
              echo "Build Determinism Check Successful"
          fi
      fi
build-determinism-release:
  needs:
    - job: build-ic-release
  parallel:
    matrix:
      - PATH0: build-ic-release/release
        PATH1: release
      - PATH0: build-ic-release/canisters
        PATH1: canisters
      - PATH0: build-ic-release/guest-os
        PATH1: guest-os/update-img
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-reproducibility"
  script:
    - |
      set -eExuo pipefail

      # TODO IDX-2757
      if [ "$CI_JOB_NAME" == "build-determinism-guest-update-img-release" ]; then
          OLD_PATH="$(git rev-parse HEAD)/build-ic-release/guest-os/update-img"
          if curl -sfSI --retry 2 "https://download.dfinity.systems/ic/$OLD_PATH/SHA256SUMS"; then
              PATH0="build-ic-release/guest-os/update-img"
          fi
      fi

      # what we've build in build-ic-release
      P0=$PATH0
      # what is live and available under $NNS_RELEASE_VERSION
      # NNS_RELEASE_VERSION is set in build-ic-release
      # shellcheck disable=SC2153
      P1="/${NNS_RELEASE_VERSION}/${PATH1}"

      ./gitlab-ci/tools/build-diff.sh "$P0" "$P1"
build-guestos-base:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/guestos/rootfs"
    IMAGE: guestos-base
    REF_FILE: ic-os/guestos/rootfs/docker-base.prod
build-guestos-base-dev:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - BUILD_ARGS=(--build-arg "PACKAGE_FILES=packages.common packages.dev")
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/guestos/rootfs"
    IMAGE: guestos-base-dev
    REF_FILE: ic-os/guestos/rootfs/docker-base.dev
build-hostos-base:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/hostos/rootfs"
    IMAGE: hostos-base
    REF_FILE: ic-os/hostos/rootfs/docker-base.prod
build-hostos-base-dev:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - BUILD_ARGS=(--build-arg "PACKAGE_FILES=packages.common packages.dev")
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/hostos/rootfs"
    IMAGE: hostos-base-dev
    REF_FILE: ic-os/hostos/rootfs/docker-base.dev
build-ic:
  artifacts:
    paths:
      - bazel-build-log*.json*
      - build-ic.tar
    reports:
      dotenv:
        - nns.release.env
  extends:
    - ".build-ic"
    - ".rules-master-pipeline-no-merge-train"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -euo pipefail
      VERSION=$(git rev-parse HEAD)

      if [[ "${CI_MERGE_REQUEST_TITLE:-}" == *"[RUN_ALL_BAZEL_TARGETS]"* ]]; then
          RUN_ON_DIFF_ONLY="false"
      fi

      if [ "$CI_JOB_NAME" == "build-ic-release" ]; then
          # read NNS release version from git tree
          NNS_RELEASE_VERSION="$(jq -r '.subnets["tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe"]' testnet/mainnet_revisions.json)"
          # we pass nss version info to build-determinism-*-release jobs
          # we put it under /tmp due to git clean -ffdx within build-ic script
          echo "NNS_RELEASE_VERSION=$NNS_RELEASE_VERSION" > /tmp/nns.release.env

          # fetch and checkout this version
          git fetch origin "$NNS_RELEASE_VERSION"
          git checkout "$NNS_RELEASE_VERSION"
          # NOTE: ic/$VERSION in S3 will have artifacts
          #       for revision $NNS_RELEASE_VERSION !!!
      fi

      if [ "$CI_COMMIT_REF_PROTECTED" == "true" ]; then
          gitlab-ci/container/build-ic.sh -i -c -b
      elif [ "${RUN_ON_DIFF_ONLY:-}" == "true" ] \
          && [ "${CI_PIPELINE_SOURCE:-}" == "merge_request_event" ] \
          && [ "${CI_MERGE_REQUEST_EVENT_TYPE:-}" != "merge_train" ] \
          && [[ "${CI_MERGE_REQUEST_TARGET_BRANCH_NAME:-}" != "rc--"* ]]; then

          TARGETS=$(gitlab-ci/src/bazel-ci/diff.sh)
          ARGS=(--no-release)

          if [ "$TARGETS" == "//..." ]; then
              ARGS+=(-i -c -b)
          else
              if grep -q "ic-os" <<<"$TARGETS"; then
                  ARGS+=(-i)
              fi
              if grep -q "publish/canisters" <<<"$TARGETS"; then
                  ARGS+=(-c)
              fi
              if grep -q "publish/binaries" <<<"$TARGETS"; then
                  ARGS+=(-b)
              fi
          fi

          if [ ${#ARGS[@]} -eq 1 ]; then
              echo "No changes that require building IC-OS, binaries or canisters."
              exit 0
          fi
          gitlab-ci/container/build-ic.sh "${ARGS[@]}"
      else
          gitlab-ci/container/build-ic.sh -i -c -b --no-release
      fi

      if [ -d artifacts/icos ]; then
          # purge test image
          find ./artifacts/icos -name 'update-img-test.*' -delete
          # only keep zstd ic images
          find ./artifacts/icos -name '*.gz' -delete
      fi

      tar -cf artifacts.tar artifacts
      URL="http://$(cat /ceph-s3-info/BUCKET_HOST)/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}"
      curl --request PUT --upload-file artifacts.tar "${URL}/artifacts.tar"

      mkdir build-ic
      for DIR in release canisters icos/guestos icos/hostos icos/setupos; do
          if [ -e "artifacts/${DIR}/SHA256SUMS" ]; then
              mkdir -p "build-ic/${DIR}/"
              cp "artifacts/${DIR}/SHA256SUMS" "build-ic/${DIR}/"
          fi
      done

      EXTERNAL_URL="https://objects.$(echo "$NODE_NAME" | cut -d'-' -f1)-idx1.dfinity.network/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}/artifacts.tar"
      echo -e "Node: ${NODE_NAME:-}\nURL: ${URL}\nExternal URL: ${EXTERNAL_URL}" >./build-ic/info
      echo "${EXTERNAL_URL}" >./build-ic/url
      tar -cf build-ic.tar build-ic

      # clean up
      bazel clean --expunge

      # collect dotenv
      if [ -f /tmp/nns.release.env ]; then
          mv /tmp/nns.release.env .
      fi
  variables:
    BAZEL_COMMAND: build
    RUN_ON_DIFF_ONLY: 'true'
build-ic-release:
  artifacts:
    paths:
      - bazel-build-log*.json*
      - build-ic.tar
    reports:
      dotenv:
        - nns.release.env
  extends:
    - ".build-ic"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-reproducibility"
  script:
    - |
      set -euo pipefail
      VERSION=$(git rev-parse HEAD)

      if [[ "${CI_MERGE_REQUEST_TITLE:-}" == *"[RUN_ALL_BAZEL_TARGETS]"* ]]; then
          RUN_ON_DIFF_ONLY="false"
      fi

      if [ "$CI_JOB_NAME" == "build-ic-release" ]; then
          # read NNS release version from git tree
          NNS_RELEASE_VERSION="$(jq -r '.subnets["tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe"]' testnet/mainnet_revisions.json)"
          # we pass nss version info to build-determinism-*-release jobs
          # we put it under /tmp due to git clean -ffdx within build-ic script
          echo "NNS_RELEASE_VERSION=$NNS_RELEASE_VERSION" > /tmp/nns.release.env

          # fetch and checkout this version
          git fetch origin "$NNS_RELEASE_VERSION"
          git checkout "$NNS_RELEASE_VERSION"
          # NOTE: ic/$VERSION in S3 will have artifacts
          #       for revision $NNS_RELEASE_VERSION !!!
      fi

      if [ "$CI_COMMIT_REF_PROTECTED" == "true" ]; then
          gitlab-ci/container/build-ic.sh -i -c -b
      elif [ "${RUN_ON_DIFF_ONLY:-}" == "true" ] \
          && [ "${CI_PIPELINE_SOURCE:-}" == "merge_request_event" ] \
          && [ "${CI_MERGE_REQUEST_EVENT_TYPE:-}" != "merge_train" ] \
          && [[ "${CI_MERGE_REQUEST_TARGET_BRANCH_NAME:-}" != "rc--"* ]]; then

          TARGETS=$(gitlab-ci/src/bazel-ci/diff.sh)
          ARGS=(--no-release)

          if [ "$TARGETS" == "//..." ]; then
              ARGS+=(-i -c -b)
          else
              if grep -q "ic-os" <<<"$TARGETS"; then
                  ARGS+=(-i)
              fi
              if grep -q "publish/canisters" <<<"$TARGETS"; then
                  ARGS+=(-c)
              fi
              if grep -q "publish/binaries" <<<"$TARGETS"; then
                  ARGS+=(-b)
              fi
          fi

          if [ ${#ARGS[@]} -eq 1 ]; then
              echo "No changes that require building IC-OS, binaries or canisters."
              exit 0
          fi
          gitlab-ci/container/build-ic.sh "${ARGS[@]}"
      else
          gitlab-ci/container/build-ic.sh -i -c -b --no-release
      fi

      if [ -d artifacts/icos ]; then
          # purge test image
          find ./artifacts/icos -name 'update-img-test.*' -delete
          # only keep zstd ic images
          find ./artifacts/icos -name '*.gz' -delete
      fi

      tar -cf artifacts.tar artifacts
      URL="http://$(cat /ceph-s3-info/BUCKET_HOST)/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}"
      curl --request PUT --upload-file artifacts.tar "${URL}/artifacts.tar"

      mkdir build-ic
      for DIR in release canisters icos/guestos icos/hostos icos/setupos; do
          if [ -e "artifacts/${DIR}/SHA256SUMS" ]; then
              mkdir -p "build-ic/${DIR}/"
              cp "artifacts/${DIR}/SHA256SUMS" "build-ic/${DIR}/"
          fi
      done

      EXTERNAL_URL="https://objects.$(echo "$NODE_NAME" | cut -d'-' -f1)-idx1.dfinity.network/$(cat /ceph-s3-info/BUCKET_NAME)/${VERSION}/${CI_JOB_ID}/artifacts.tar"
      echo -e "Node: ${NODE_NAME:-}\nURL: ${URL}\nExternal URL: ${EXTERNAL_URL}" >./build-ic/info
      echo "${EXTERNAL_URL}" >./build-ic/url
      tar -cf build-ic.tar build-ic

      # clean up
      bazel clean --expunge

      # collect dotenv
      if [ -f /tmp/nns.release.env ]; then
          mv /tmp/nns.release.env .
      fi
build-setupos-base:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/setupos/rootfs"
    IMAGE: setupos-base
    REF_FILE: ic-os/setupos/rootfs/docker-base.prod
build-setupos-base-dev:
  artifacts:
    paths:
      - digestfile*
  extends:
    - ".build-base-image-job"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "build-push-base-images"
    - allow_failure: true
      if: $CI_COMMIT_BRANCH == "master" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
    - changes:
        - gitlab-ci/config/base-images-build.yml
        - ic-os/boundary-guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/Dockerfile.base
        - ic-os/guestos/rootfs/packages.common
        - ic-os/guestos/rootfs/packages.dev
        - ic-os/hostos/rootfs/Dockerfile.base
        - ic-os/hostos/rootfs/packages.common
        - ic-os/hostos/rootfs/packages.dev
        - ic-os/setupos/rootfs/Dockerfile.base
        - ic-os/setupos/rootfs/packages.common
        - ic-os/setupos/rootfs/packages.dev
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - BUILD_ARGS=(--build-arg "PACKAGE_FILES=packages.common packages.dev")
    - |
      set -euo pipefail

      TAG=$(date '+%Y-%m-%d-%H%M')
      echo -e "\e[0Ksection_start:$(date +%s):${IMAGE}[collapsed=true]\r\e[0KClick here to see the ${IMAGE} build"
      pushd "$CONTEXT"
      podman build "${BUILD_ARGS[@]}" --squash-all --no-cache -t "docker.io/dfinity/${IMAGE}:${TAG}" -f Dockerfile.base .
      popd
      echo -e "\e[0Ksection_end:$(date +%s):${IMAGE}\r\e[0K"

      if [ "${CI_COMMIT_REF_NAME:-}" == "master" ]; then
          podman login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD" docker.io
          podman push "dfinity/${IMAGE}:${TAG}" --digestfile digestfile
          echo "dfinity/${IMAGE}@$(cat digestfile)" > "digestfile-${IMAGE}"
          echo "$REF_FILE" >> "digestfile-${IMAGE}"
          rm -f digestfile
      fi
  variables:
    CONTEXT: "${CI_PROJECT_DIR}/ic-os/setupos/rootfs"
    IMAGE: setupos-base-dev
    REF_FILE: ic-os/setupos/rootfs/docker-base.dev
cargo-build-release-linux:
  extends:
    - ".rules-master-pipeline-and-merge-request-rust-changed"
  needs: []
  rules:
    - changes:
        - "**/*.rs"
        - "**/*.toml"
        - "**/*.lock"
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- cargo build --release
cargo-clippy-linux:
  extends:
    - ".rules-master-pipeline-and-merge-request-rust-changed"
  needs: []
  rules:
    - changes:
        - "**/*.rs"
        - "**/*.toml"
        - "**/*.lock"
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -eExuo pipefail
      buildevents cmd "$ROOT_PIPELINE_ID" "$CI_JOB_ID" build-command -- \
          "$CI_PROJECT_DIR"/gitlab-ci/src/rust_lint/lint.sh
  variables:
    CARGO_BUILD_TARGET: x86_64-unknown-linux-gnu
commit-lint:
  needs: []
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - "./gitlab-ci/src/ci-scripts/commit-lint.sh"
container-autobuild:
  needs: []
  rules:
    - changes:
        - ".bazelversion"
        - gitlab-ci/container/**/*
        - gitlab-ci/config/container-image-autobuild.yml
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -euo pipefail

      # safeguard for feedback loop [this CI job pushes commits]
      git fetch origin master
      COMMIT_COUNT=$(git rev-list --count "$(git merge-base HEAD origin/master)"..HEAD)
      if [ "$COMMIT_COUNT" -gt 256 ]; then
          echo "Reached hard safeguard limit of commits"
          exit 1
      fi

      # check if tag changed
      pushd gitlab-ci/container
      TAG="$(./get-image-tag.sh)"
      cd ../config
      # names must match with names in docker-build-image.sh!
      IMG_BAZEL_NAME="registry.gitlab.com/dfinity-lab/core/docker/ic-build"
      IMG_BAZEL_DOCKER_HUB="dfinity/ic-build"

      IMG_BAZEL_NAME_FULL="$IMG_BAZEL_NAME:$TAG"
      IMG_BAZEL_DOCKER_HUB_FULL="$IMG_BAZEL_DOCKER_HUB:$TAG"

      # return if no changes
      if grep -q "$IMG_BAZEL_NAME_FULL" -- *; then
          echo "No changes required to build a new docker ic-build image"
          exit 0
      fi
      popd

      # build new ic-build* images
      ./gitlab-ci/container/build-image.sh

      # push the new ic-build image it to gitlab registry
      docker login -u gitlab-ci-token -p "$GITLAB_API_TOKEN" registry.gitlab.com
      docker push "$IMG_BAZEL_NAME_FULL"
      # clean-up
      docker image prune -f
      docker container prune -f

      # update gitlab's docker image tags
      pushd gitlab-ci/config
      sed -i -E "s|$IMG_BAZEL_NAME:[^\"]{5,}|$IMG_BAZEL_NAME_FULL|g" -- *
      cd ../container
      echo "$TAG" > TAG
      popd

      pushd .devcontainer
      sed -i -E "s|$IMG_BAZEL_DOCKER_HUB:[^\"]{5,}|$IMG_BAZEL_DOCKER_HUB_FULL|g" -- *
      popd

      # update github CI docker image
      pushd .github
      sed -i -E "s|$IMG_BAZEL_DOCKER_HUB:[^\"]{5,}|$IMG_BAZEL_DOCKER_HUB_FULL|g" -- workflow*/*
      popd

      # commit and push the change upstream
      git config --global user.email "idx@dfinity.org"
      git config --global user.name "IDX GitLab Automation"
      git commit -a -m "Updating docker image in CI"
      git remote add origin \
          "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" \
          || true
      git remote set-url origin \
          "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" \
          || true
      git push --set-upstream origin HEAD:"$CI_COMMIT_REF_NAME"
container-autobuild-protected:
  needs: []
  rules:
    - changes:
        - gitlab-ci/container/TAG
      if: $CI_COMMIT_REF_PROTECTED == "true" && $CI_PIPELINE_SOURCE == "push"
    - if: $CI_COMMIT_REF_PROTECTED == "true" && $SCHEDULE_NAME == "run-all-master"
  script:
    - |
      # use docker on protected runner
      set -euo pipefail

      # container image tag
      TAG=$(cat ./gitlab-ci/container/TAG)
      # check if we have it in dockerhub
      EXISTS_BAZEL=$(curl -s https://hub.docker.com/v2/repositories/dfinity/ic-build/tags | jq -r "[.results? | .[]? | .name == \"$TAG\"] | any")

      if [ "$EXISTS_BAZEL" != "true" ]; then
        # build it
        echo -e "\e[0Ksection_start:$(date +%s):docker_build_script[collapsed=true]\r\e[0KClick here to see the docker_build_script"
        ./gitlab-ci/container/build-image.sh
        echo -e "\e[0Ksection_end:$(date +%s):docker_build_script\r\e[0K"
        # push it to dockerhub
        docker login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"
        docker push docker.io/dfinity/ic-build:"$TAG"
        docker push docker.io/dfinity/ic-build:latest
        # clean-up
        docker image prune -f
        docker container prune -f
      fi
cut-release-candidate:
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "release-candidate-cut"
  script:
    - |
      # The remote might already exist from a previous CI job run because GitLab re-uses the git repo.
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      RC_BRANCH_NAME="rc--$(date '+%Y-%m-%d_%H-%M')"
      git switch --force-create "$RC_BRANCH_NAME" HEAD
      git push --force --set-upstream origin  "$RC_BRANCH_NAME"
default:
  artifacts:
    expire_in: 3 days
    when: always
  image:
    name: registry.gitlab.com/dfinity-lab/core/docker/ic-build:e95ed63e9addda1b335c50fde800a8d9f0aad91a0d0cbe7da2fa782dc6ac1d4c
  interruptible: true
  retry:
    max: 2
    when:
      - unknown_failure
      - api_failure
      - runner_system_failure
  tags:
    - dfinity-ic
delegated-identity-bench:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_delegation_experiment.py --testnet $TESTNET --num_procs 64 --iter_duration 30 --num_identities 200 --rps 30,100,200,500,1000

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"

      cd -
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
dependencies-check:
  allow_failure: false
  extends:
    - ".rules-master-pipeline-no-merge-train-rust-bazel-changed"
  needs: []
  rules:
    - changes:
        - ".bazelrc"
        - ".bazelversion"
        - "**/*.bazel"
        - "**/*.bzl"
        - "**/*.lock"
        - "**/*.rs"
        - "**/*.toml"
        - gitlab-ci/container/Dockerfile
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -euo pipefail
      pip3 install --ignore-installed -r requirements.txt
      cd "${CI_PROJECT_DIR}"/gitlab-ci/src/dependencies/
      $SHELL_WRAPPER python3 job/bazel_rust_ic_scanner_merge_job.py
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
    SHELL_WRAPPER: "/usr/bin/time"
dependency-scan-nightly:
  allow_failure: true
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "dependency-scan-nightly"
  script:
    - |
      set -euo pipefail
      pip3 install --ignore-installed -r requirements.txt
      $SHELL_WRAPPER cargo install wasm-pack --version "${CARGO_WASMPACK_VERSION}"
      # shellcheck disable=SC1090
      source "${NVM_DIR}/nvm.sh"
      nvm use ${DEFAULT_NODE_VERSION}
      node --version
      npm --version
      cd "${CI_PROJECT_DIR}"/gitlab-ci/src/dependencies
      $SHELL_WRAPPER python3 job/bazel_rust_ic_scanner_periodic_job.py
      $SHELL_WRAPPER python3 job/npm_scanner_periodic_job.py
      $SHELL_WRAPPER python3 job/bazel_trivy_container_ic_scanner_periodic_job.py
  variables:
    CARGO_WASMPACK_VERSION: 0.12.1
    DEFAULT_NODE_VERSION: '20'
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
    SHELL_WRAPPER: "/usr/bin/time"
dependency-scan-release-cut:
  allow_failure: false
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -euo pipefail
      pip3 install --ignore-installed -r requirements.txt
      cd "${CI_PROJECT_DIR}"/gitlab-ci/src/dependencies
      $SHELL_WRAPPER python3 job/bazel_rust_ic_scanner_release_job.py
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
    SHELL_WRAPPER: "/usr/bin/time"
heavy-memory-update-performance-test-nightly:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-spot-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch

      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes

      # Run heavy memory update performance evaluation
      cd ./scalability

      $SHELL_WRAPPER timeout 1h python3 experiments/run_large_memory_experiment.py --testnet "$TESTNET" --wg_testnet "$TESTNET" --wg_subnet 2 --iter_duration 300 --target_rps=15 --use_updates=True

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
large-response-downloading-nightly:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-spot-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch

      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes

      cd ./scalability

      $SHELL_WRAPPER timeout 1h python3 experiments/run_large_payload_experiment.py --testnet "$TESTNET" --wg_testnet "$TESTNET" --wg_subnet 2 --iter_duration 300 --datapoints 2048

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)

      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      $SHELL_WRAPPER python3 common/verify_perf.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP" --median_latency_threshold=3300

      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
lock-generate:
  needs: []
  rules:
    - changes:
        - gitlab-ci/config/main.yml
        - ".bazelrc"
        - ".bazelversion"
        - "**/*.bazel"
        - "**/*.bzl"
        - "**/*.lock"
        - "**/*.rs"
        - "**/*.toml"
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - "./gitlab-ci/src/ci-scripts/lock-generate.sh"
  tags:
    - dfinity-ic
    - bazel
maximum-capacity-boundary-nodes-queries:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --boundary-dev-image
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_boundary_node_baseline_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --targets https://"$TESTNET".testnet.dfinity.network --use_updates=False --no_instrument=True --datapoints=100~2000~5000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
      cd -
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-canister-http:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      echo '{"test_ledger_accounts":["b3gus-edhie-77egn-fejju-pt4xd-zz2pt-7v22l-rrts4-a3ebi-fcm4d-wae"]}' > test-accounts.json
      export TESTNET_LOG="testnet_deployment.log"
      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh "$TESTNET" --git-revision "$GIT_REVISION" --no-boundary-nodes  --ansible-args "-e @$PWD/test-accounts.json" &> $TESTNET_LOG

      # Obtains nns_node URL
      NNS_URL=$(grep "NNS_URL" "$TESTNET_LOG" | tail -1 | grep -o -P '(?<=http).*(?=8080)' | sed 's/$/8080/' | sed 's/^/http/')
      echo "$NNS_URL" > nns_url.log
      echo "Obtained NNS subnet URL: $NNS_URL"

      # Enables http_request feature on subnet
      "$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/rclone_download.py \
          --git-rev="$GIT_REVISION" --remote-path="release" \
          --out="artifacts/release"
      gzip -d "${CI_PROJECT_DIR}/artifacts/release/ic-admin.gz"
      chmod u+x "${CI_PROJECT_DIR}/artifacts/release/ic-admin"
      ln -sf "${CI_PROJECT_DIR}/artifacts/release/ic-admin" ic-admin
      "${CI_PROJECT_DIR}/artifacts/release/ic-admin" --nns-url="$NNS_URL" propose-to-update-subnet --features http_requests --subnet 1 --test-neuron-proposer --summary "Updating a subnet"

      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_mixed_workload_experiment.py --testnet "$TESTNET" --wg_testnet "$TESTNET" --wg_subnet 2 --initial_rps=50 --increment_rps=50 --target_rps=150 --max_rps=400 --workload workloads/canister-http-benchmark.toml

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-large-memory-query:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_large_memory_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --initial_rps=20 --increment_rps=5 --target_rps=160 --max_rps=1000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-large-memory-update:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_large_memory_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --use_updates=True --datapoints=20,35,50,55,100,150

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-mixed-counter-memory:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      # These are equivalent to maximum-capacity-large-memory-update.
      # We just run the counter canister alongside it.
      # Might mean that we don't need maximum-capacity-large-memory-update any longer.
      $SHELL_WRAPPER python3 experiments/run_mixed_workload_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --workload workloads/mixed-memory-counter.toml --initial_rps=10 --increment_rps=5 --target_rps=25 --max_rps=500

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-mixed-workloads:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_mixed_workload_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --workload workloads/mixed-query-update.toml --initial_rps=20 --increment_rps=5 --target_rps=160 --max_rps=1000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-multiple-large-memory-update:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_large_memory_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --use_updates=True --initial_rps=20 --increment_rps=10 --target_rps=25 --max_rps=100 --num_canisters 15 --payload_size 5000000 --use_updates=True --iter_duration 900

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-qr:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER experiments/run_mixed_workload_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --workload workloads/qr.toml --initial_rps=10 --increment_rps=5 --target_rps=25 --max_rps=150

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-sha256:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER experiments/run_mixed_workload_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --workload workloads/sha256.toml --initial_rps=10 --increment_rps=5 --target_rps=25 --max_rps=150

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-system-baseline-query:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      # First run, no caching
      # -------------------------------------------------

      $SHELL_WRAPPER python3 experiments/run_system_baseline_experiment.py --use_random_payload=True --num_canisters 2 --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --datapoints 100,3500,4500,5500,7500,12000,17200,40000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      # Allow the system some time to recover from previous benchmark
      sleep 60

      # Second run, with caching
      # -------------------------------------------------

      $SHELL_WRAPPER python3 experiments/run_system_baseline_experiment.py --num_canisters 2 --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --datapoints 100,3500,4500,5500,7500,12000,17200,40000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      # Upload results from both run (the entire folder of that GIT revision)
      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
maximum-capacity-system-baseline-update:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_system_baseline_experiment.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET --use_updates=True --initial_rps=100 --increment_rps=20 --target_rps=800 --max_rps=2000

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip
      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
no-interrupt:
  interruptible: false
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
  script:
    - echo "This pipeline is not interruptible"
notify-gitlab-failure:
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/
      when: on_failure
  script:
    - "pip3 install --ignore-installed -r requirements.txt\n\necho \"notify gitlab failure\"\nif [[ \"${CI_COMMIT_MESSAGE,,}\" =~ hotfix ]]; then\n    MESSAGE=\"✘ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. \U0001F336\U0001F336\U0001F336\"\nelse\n    MESSAGE=\"❌ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> failed. \U0001F62D\U0001F62D\U0001F62D\"\nfi\ncd \"${CI_PROJECT_DIR}/gitlab-ci/src\" || true\nbuildevents cmd \"$ROOT_PIPELINE_ID\" \"$CI_JOB_ID\" notify-slack -- notify_slack/notify_slack.py \\\n    \"${MESSAGE}\" --channel \"release-management-alerts\"\n"
  stage: finalize
notify-gitlab-success:
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: on_success
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^rc--/
      when: on_success
  script:
    - "pip3 install --ignore-installed -r requirements.txt\n\n# TODO(IDX-2856): remove this top level \"if\" when we will not need to run the job for schedule pipelines.\nif [[ \"$CI_PIPELINE_SOURCE\" == \"push\" ]] && [[ \"$CI_COMMIT_REF_NAME\" =~ ^rc--.* ]]; then\n  if [[ \"${CI_COMMIT_MESSAGE,,}\" =~ hotfix ]]; then\n      MESSAGE=\"✔ Hotfix pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. \U0001FAD1\U0001FAD1\U0001FAD1\"\n  else\n      MESSAGE=\"✅ Release candidate pipeline <$CI_PIPELINE_URL|$CI_COMMIT_REF_NAME> succeeded. \U0001F389\U0001F389\U0001F389\"\n  fi\n  cd \"${CI_PROJECT_DIR}/gitlab-ci/src\" || true\n  buildevents cmd \"$ROOT_PIPELINE_ID\" \"$CI_JOB_ID\" notify-slack -- notify_slack/notify_slack.py \\\n    \"${MESSAGE}\" --channel \"release-management-alerts\"\nfi\n"
  stage: finalize
pre-commit:
  extends:
    - ".rules-master-pipeline-and-merge-request"
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -eEuo pipefail

      rustup default stable

      pip3 install pre-commit

      # Make sure CI can pull from the private repo.
      if ! SKIP=bazel_rust_format_check,bazel_smoke pre-commit run -a --hook-stage=manual ; then
        echo "Pre-commit checks failed. Here is the diff of the changes:"
        git diff
        echo
        echo "You can fix the code locally by following these instructions in the same branch."
        echo
        echo "install pre-commit by following https://pre-commit.com/#installation:"
        echo "(brew|pip) install pre-commit"
        echo "pre-commit install"
        echo
        echo "Then, to fix the checks in this branch, run:"
        echo "pre-commit run --from-ref=\$(git merge-base HEAD master) --to-ref=HEAD"
        echo
        echo "And then commit the changes."
        exit 1
      fi
  tags:
    - dfinity-ic
    - bazel
  variables:
    PRE_COMMIT_HOME: "/cache/pre-commit/$CI_CONCURRENT_ID"
python-ci-tests:
  artifacts:
    paths:
      - gitlab-ci/src/htmlcov
    reports:
      junit:
        - test_report.xml
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH =~ /^(rc--|hotfix-.+-rc--).+/
  script:
    - |
      set -xeuo pipefail
      pip3 install --ignore-installed -r requirements.txt
      cd gitlab-ci/src
      pytest --ignore=gitlab_config/ -v -o junit_family=xunit1 --junitxml=../../test_report.xml --cov=. --cov-report=term --cov-report=term-missing --cov-report=html --cov-branch
  variables:
    PYTHONPATH: "${CI_PROJECT_DIR}/gitlab-ci/src:${CI_PROJECT_DIR}/gitlab-ci/src/dependencies"
rosetta-api-docker-image:
  needs:
    - artifacts: false
      job: bazel-test-all
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: manual
  script:
    - |
      set -exuo pipefail

      pip3 install --ignore-installed -r requirements.txt

      "${CI_PROJECT_DIR}"/gitlab-ci/src/artifacts/rclone_download.py --git-rev "$CI_COMMIT_SHA" \
        --remote-path=release --out="artifacts/release"

      gunzip artifacts/release/ic-rosetta-api.gz
      chmod +x artifacts/release/ic-rosetta-api

      pushd "$(mktemp -d)"
      cp \
        "$CI_PROJECT_DIR"/artifacts/release/ic-rosetta-api \
        .
      docker build \
        --build-arg RELEASE="$CI_COMMIT_SHA" \
        -f "$CI_PROJECT_DIR"/rs/rosetta-api/Dockerfile \
        -t dfinity/rosetta-api:"$CI_COMMIT_SHA" \
        .
      popd

      docker run --rm dfinity/rosetta-api:"$CI_COMMIT_SHA" --help

      ROSETTA_API_DATE=$(date +"%Y%m%d")
      ROSETTA_API_VERSION=$(grep -e '^version' "$CI_PROJECT_DIR"/rs/rosetta-api/Cargo.toml | sed -e 's|^version[ ]*=[ ]*"\([^"]*\)"|\1|g')

      docker tag dfinity/rosetta-api:"$CI_COMMIT_SHA" dfinity/rosetta-api:"$ROSETTA_API_DATE"
      docker tag dfinity/rosetta-api:"$CI_COMMIT_SHA" dfinity/rosetta-api:v"$ROSETTA_API_VERSION"
      docker tag dfinity/rosetta-api:"$CI_COMMIT_SHA" dfinity/rosetta-api:latest

      docker login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"

      docker push dfinity/rosetta-api:"$CI_COMMIT_SHA"
      docker push dfinity/rosetta-api:"$ROSETTA_API_DATE"
      docker push dfinity/rosetta-api:v"$ROSETTA_API_VERSION"
      docker push dfinity/rosetta-api:latest
rosetta-icrc-release:
  rules:
    - if: $CI_COMMIT_REF_PROTECTED == "true" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "rosetta-icrc-release"
  script:
    - |
      set -euo pipefail

      docker login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"
      docker-bin login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"

      # - Query the current rosetta version
      bazel build //rs/rosetta-api/icrc1/rosetta:version
      readonly ICRC_ROSETTA_RELEASE_VERSION="$(cat "$(bazel cquery --output=files //rs/rosetta-api/icrc1/rosetta:version)")"
      readonly VERSION_TAG="v$ICRC_ROSETTA_RELEASE_VERSION"

      # - Abort the release if the image with that version was already published.
      if docker manifest inspect "docker.io/dfinity/ic-icrc-rosetta-api:$VERSION_TAG"; then
          echo Rosetta version "$ICRC_ROSETTA_RELEASE_VERSION" is already published on DockerHub
          exit 0
      fi

      for tag in "$VERSION_TAG" latest; do
          bazel run --stamp --embed_label="$tag" //rs/rosetta-api/icrc1/rosetta:push_ic_icrc_rosetta_image
      done

      # - Tag the commit
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      git tag "rosetta-icrc-release-$ICRC_ROSETTA_RELEASE_VERSION" "$CI_COMMIT_SHA"
      git push origin "rosetta-icrc-release-$ICRC_ROSETTA_RELEASE_VERSION"
rosetta-release:
  rules:
    - if: $CI_COMMIT_REF_PROTECTED == "true" && $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "rosetta-release"
  script:
    - |
      set -euo pipefail

      docker login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"
      docker-bin login -u "$DOCKER_HUB_USER" -p "$DOCKER_HUB_PASSWORD"

      # - Query the current rosetta version
      bazel build //rs/rosetta-api:version
      readonly ROSETTA_RELEASE_VERSION="$(cat "$(bazel cquery --output=files //rs/rosetta-api:version)")"
      readonly VERSION_TAG="v$ROSETTA_RELEASE_VERSION"

      # - Abort the release if the image with that version was already published.
      if docker manifest inspect "docker.io/dfinity/rosetta-api:$VERSION_TAG"; then
          echo Rosetta version "$ROSETTA_RELEASE_VERSION" is already published on DockerHub
          exit 0
      fi

      # - Build an publish the image
      ROSETTA_API_DATE=$(date +"%Y%m%d")

      for tag in "$VERSION_TAG" "$CI_COMMIT_SHA" "$ROSETTA_API_DATE" latest; do
          bazel run --stamp --embed_label="$tag" //rs/rosetta-api:push_rosetta_image
      done

      # - Tag the commit
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      git tag "rosetta-release-$ROSETTA_RELEASE_VERSION" "$CI_COMMIT_SHA"
      git push origin "rosetta-release-$ROSETTA_RELEASE_VERSION"
stages:
  - ".pre"
  - init
  - test
  - finalize
  - ".post"
statesync-experiment:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      # Note that this benchmark needs unassigned nodes
      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --dkg-interval-length 14 --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER python3 experiments/run_statesync_experiment.py --testnet $TESTNET

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
system-baseline-query-performance-test-nightly:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-spot-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch

      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      # Note that this benchmark needs unassigned nodes
      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes

      # Run system baseline performance evaluation
      cd ./scalability

      $SHELL_WRAPPER timeout 1h python3 experiments/run_system_baseline_experiment.py --testnet "$TESTNET" --wg_subnet 2 --wg_testnet $TESTNET --iter_duration 300 --target_rps=600  --use_updates=False

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"
      $SHELL_WRAPPER python3 common/verify_perf.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP" --median_latency_threshold=200

      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
system-baseline-update-performance-test-nightly:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-spot-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch

      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      # Note that this benchmark needs unassigned nodes
      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes

      # Run system baseline performance evaluation
      cd ./scalability

      $SHELL_WRAPPER timeout 1h python3 experiments/run_system_baseline_experiment.py --testnet "$TESTNET" --wg_subnet 2 --wg_testnet $TESTNET --iter_duration 300 --target_rps=60 --use_updates=True

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"
      $SHELL_WRAPPER python3 common/verify_perf.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP" --median_latency_threshold=2300

      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
tecdsa:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_SUITE"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch
      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes
      cd ./scalability

      $SHELL_WRAPPER experiments/run_tecdsa.py --testnet $TESTNET --wg_subnet 2 --wg_testnet $TESTNET

      # TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)
      # $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      find . -name  'workload-generator*stderr.txt' -print0 | xargs -0 gzip

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
      cd -
  timeout: 3 hours
  variables:
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdslo
test-push-branch:
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "run-all-master"
      when: on_success
  script:
    - |
      # The remote might already exist from a previous CI job run because GitLab re-uses the git repo.
      git remote add origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true
      git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git" || true

      git config --global user.email "infra+gitlab-automation@dfinity.org"
      git config --global user.name "IDX GitLab Automation"

      git switch --force-create post-merge-tests-passed HEAD
      git push --force --set-upstream origin post-merge-tests-passed
variables:
  GET_SOURCES_ATTEMPTS: 5
  GIT_CLONE_PATH: "$CI_BUILDS_DIR/clean/$CI_PROJECT_NAME"
  GIT_DEPTH: 0
  GIT_STRATEGY: fetch
  TEST_ES_HOSTNAMES: elasticsearch.testnet.dfinity.network:443
xnet-nightly:
  artifacts:
    paths:
      - scalability/
    when: always
  dependencies: []
  extends: ".benchmark-spot-test"
  resource_group: "$TESTNET"
  rules:
    - allow_failure: true
      if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /\[benchmark\]/
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "BENCHMARK_NIGHTLY"
      when: always
  script:
    - |
      set -eExou pipefail
      git fetch

      GIT_REVISION=$("$CI_PROJECT_DIR"/gitlab-ci/src/artifacts/newest_sha_with_disk_image.sh "$DISKIMG_BRANCH")

      pip3 install --ignore-installed -r requirements.txt

      $SHELL_WRAPPER timeout 1h ./testnet/tools/icos_deploy.sh $TESTNET --git-revision "$GIT_REVISION" --no-boundary-nodes

      cd ./scalability

      $SHELL_WRAPPER timeout 1h python3 experiments/run_xnet_experiment.py --testnet "$TESTNET" --iter_duration 300 --datapoints=500

      TIMESTAMP=$(find results/"$GIT_REVISION" -maxdepth 1 -mindepth 1 -type d -printf "%f\n" | sort -nr | head -1)

      $SHELL_WRAPPER python3 common/generate_report.py --base_dir="results/" --git_revision="$GIT_REVISION" --timestamp="$TIMESTAMP"

      cd -

      $SHELL_WRAPPER rclone --config="${CI_PROJECT_DIR}/.rclone.conf"  copyto "scalability/results/$GIT_REVISION" "performance-testing:performance-testing-results/$GIT_REVISION"
  timeout: 1 hour
  variables:
    CD_ENV: BENCHMARK_NIGHTLY
    CURRENT_BRANCH: "$CI_COMMIT_REF_NAME"
    DISKIMG_BRANCH: "${CI_COMMIT_SHA}"
    PARENT_PIPELINE_ID: "${CI_PIPELINE_ID}"
    SHELL_WRAPPER: "/usr/bin/time"
    TESTNET: cdrc02
    WG_TESTNET: cdrc02
    cd_target_env: BENCHMARK_NIGHTLY
zz-generated-gitlab:
  needs: []
  rules:
    - changes:
        - gitlab-ci/config/**/*
        - ".gitlab-ci.yml"
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - |
      set -eEuo pipefail

      output_file="gitlab-ci/config/zz-generated-gitlab-ci.yaml"

      curl -G "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/ci/lint" \
          -d "dry_run=true" \
          -d "include_jobs=true" \
          -d "ref=$CI_COMMIT_REF_NAME" \
          -H "Authorization: Bearer $GITLAB_API_TOKEN" | jq -r '.merged_yaml' >"$output_file"

      yq  'sort_keys(...)' -i "$output_file"

      if [ -n "$(git status --porcelain)" ]; then
          git config --global user.email "idx@dfinity.org"
          git config --global user.name "IDX GitLab Automation"
          git commit -am "Updating $output_file"
          git remote set-url origin "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/${CI_PROJECT_PATH}.git"
          git push --set-upstream origin HEAD:"$CI_COMMIT_REF_NAME"
      else
          echo "git working tree clean - no changes to be committed"
      fi
