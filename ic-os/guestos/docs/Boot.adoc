= IC guest OS boot sequence

The system boot starts with the initramfs which performs some preparatory
operations already. It takes a first look at the +/config+ filesystem to
load a machine-id file if it exists. If it is found, then it is bind-mounted
on top of the root filesystem to provide the machine-id in subsequent boot
(and which would otherwise be randomly generated by systemd once it takes
over). This ensures stability of machine-id after first boot.

After switch to the proper root filesystem, the following essential IC-specific services are started in the IC-OS boot sequence:

- Mount +/boot+ filesystems (including +/boot/config+)

- Mount configuration media (+mount-config.service+)

- Save machine-id

- Set up ssh host keys

- Set up node exporter keys

- Set up key for block device encryption

- Set up and mount +/var+ filesystem

- Set up of logical volume manager

- One-time set up of filesystems in LVs

- Mount of file systems in LVs

- Initialize IC node configuration (+init-config.service+)

- IC node bootstrap (+bootstrap-ic-node.service+)

- Set up ssh user keys

- Generate network configuration

- Set up hostname

- IPv6 address monitor / retry

- Upgrade data store

- nftables reload on change

- Start node exporter

== Kernel Command Line Parameters

We calculate kernel command line parameters at build time.

=== boot_args.template

The `boot_args.template` file in the GuestOS context directory defines the kernel command line parameters used when booting the GuestOS. This file contains two variables:

* `BOOT_ARGS_A`: Kernel command line parameters for booting from partition set A
* `BOOT_ARGS_B`: Kernel command line parameters for booting from partition set B

=== During the boot process

1. The GRUB bootloader checks for the existence of a `boot_args` file on the boot partition.
2. If found, it sources this file to get the appropriate boot arguments based on the active partition set (A or B).

== Mount +/boot+ filesystems

The partition used to be mounted as +/boot+ depends on the partition
set that we are booting from (see link:DiskLayout{outfilesuffix}[disk layout]
for description of partition layout). The mount description for +/boot+ is therefore
not held in +/etc/fstab+ but is generated by the shell script
+/etc/systemd/system-generators/mount-generator+.

Afterwards, the first three partitions are mounted as +/boot/efi+, +/boot/grub+
and +/boot/config+, respectively. The +config+ partition is
used as (small) store for data that is preserved across upgrades
and is available at early boot time already.

== Mount configuration media

Service: +mount-config.service+, script: +/opt/ic/bin/mount-config.sh+.

This service locates and mounts the configuration device (removable media, device with serial "config", or filesystem labeled "CONFIG") to +/mnt/config+.
The configuration device is used to supply bootstrap information and initial configuration files to the system.

== Save machine-id

If a machine-id was randomly generated (as happens on first boot), it is saved
away to the +/boot/config+ partition such that it can be restored during
next boot and ensure it is stable across both reboots and upgrades. This
must be restored on next boot from initrd as the root filesystem is read-only
and systemd has no other way of stashing it away otherwise.

== Set up key for block device encryption

Service: +setup-data-encryption.service+, script: +/opt/ic/bin/setup-encryption.sh+,
depends on +/boot/config+ mount. cryptsetup for +/dev/vda10+ depends on this.

The initially deployed image has only 9 partitions set up. The 10th partition
of the running system is to take up the entire "remainder" of the disk and
be used as encrypted payload storage.

At first boot after deployment, the missing 10th partition will be created,
an encryption key will be generated, and the partition will be set up as
encrypted storage.

== Set up and mount +/var+ filesystem

Partition numbers 6 or 9 (for system A and system B, respectively) are used
for the +/var+ filesystem hierarchy. It is set up as an encrypted filesystem
as well, but its lifetime is limited to the system that it is associated with:
If system A is upgraded to system B, then the +/var+ partition associated of
system B is set up from scratch on first boot of system B. The (now unused)
+/var+ partition of system A will be scrapped and overwritten on next upgrade
written into system A again.

The partition is set up as an encrypted partition as well (since IC intermediary
data might leak to it). This is facilitated in the following way:

* The script +/opt/ic/bin/setup-var-encryption.sh+ will check if the partition
  is set up correctly already. If it is, then it is used as-is.
  Otherwise, it is reformatted as an encrypted partition, and a filesystem
  is put in. The filesystem is initialized from the filesystem state of
  the /var subtree that is part of the root filesystem. (So this effectively
  serves as a template defining initial structure of /var).

* The unit file triggering this script is dynamically generated through
  +/etc/systemd/system-generators/mount-generator+: The generator will
  check which partition is the correct one to use and synthesize a proper
  unit file.

When an upgrade is installed into either system slot A or B, it is ensured
that the corresponding +/var+ partition is wiped such that the newly booted
system will set up its own +/var+ filesystem correctly again.

== Set up ssh host keys

Service: +generate-host-ssh-keys.service+, script: +/opt/ic/bin/generate-host-ssh-keys.sh+,
depends on +/boot/config+ mount.

This checks if ssh host keys for the system exist in the +config+ partition
(creating them if necessary -- only on first boot after deployment). The
keys are then copied to tmpfs and bind-mounted to +/etc/ssh+. Keeping
host keys in the +config+ partition ensures that they are stable across
system upgrades.

== Set up node exporter keys

Service: +setup-node_exporter-keys.service+, script +/opt/ic/bin/setup-node_exporter-keys.sh+,
depends on +/boot/config+ mount.

This generates the TLS key pair for the +node_exporter+ service on first boot.
The keys are then bind-mounted into a suitable location within +/etc+.

Similar to the ssh keys, the keys are held in the +config+ partition such that
they are persisted across upgrades and available in early boot.

== Set up of logical volume manager

Service: +setup-lvs.service+, script: +/opt/ic/bin/setup-lvs.sh+, depends
on cryptsetup for +/dev/vda10+.

This ensure that the volume group +store+ exists (creating it if it does
not -- this is a one-time action on first boot after provisioning)
and is activated. It then ensure that logical volumes +store/shared-crypto+,
+store/shared-backup+ and +/store/shared-data+ exist (again creating them
if needed, one-time action after boot). These will be used
to hold data that is persisted across backups and held encrypted.

== One-time setup of filesystems in LVs

Services: +setup-shared-data.service+, +setup-shared-crypto.service+, +setup-shared-backup.service+,
scripts +/opt/ic/bin/setup-shared-data.sh+, +/opt/ic/bin/setup-shared-crypto.sh+, +/opt/bin/setup-shared-backup.sh+.
Depend on set up of logical volume manager. Mounts of filesystems in LVs
depend on this.

This checks whether correct filesystems are already set up in the
logical volumes and creates them if not (one-time set up after
provisioning).

== Mount of file systems in LVs

The filesystems mounts are defined in +/etc/fstab+, it is ensured via
dependencies that set up of LVs completes before +fsck+ and +mount+
of these.

== Initialize IC node configuration

Service: +init-config.service+, script +/opt/ic/bin/init-config.sh+, depends on +mount-config.service+ and requires +/mnt/config+ mount.

This service initializes configuration in +/run/config/config.json+ from the bootstrap package.

== IC node bootstrap

Service: +bootstrap-ic-node.service+, depends on +mount-config.service+ and +init-config.service+ and requires
+/boot/config+,  +/var/lib/ic/data+, and +/var/lib/ic/crypto+ mounts.

This service is only executed once on first boot after provisioning.
It looks for
+ic-bootstrap.tar+ file at +/mnt/config/ic-bootstrap.tar+ that contains initial configuration for the system.
Required files in the +config+ partition as well as payload store are created from this bootstrap package.

The bootstrap process populates SSH keys, +/var/lib/ic/data+, and +/var/lib/ic/crypto+
with the necessary configuration for the IC node to operate.

== Set up ssh user keys

Service: +setup-ssh-user-keys.services+, script +/opt/ic/bin/setup-ssh-user-keys.sh+.
Depends on +bootstrap-ic-node.service+.

The +authorized_keys+ files for the role accounts are taken from the
config partition and bind-mounted into the correct locations in
the account user home directories.

== Generate network configuration

Service: +generate-network-config.service+
Depends on +bootstrap-ic-node.service+, runs before +systemd-networkd.service+.

This parses the network configuration given in the +config+ partition and
generates network configuration directives for +systemd-networkd+ to apply
later.

== Set up hostname

Service: +generate-network-config.service+
Depends on +bootstrap-ic-node.service+, runs before +systemd-networkd.service+.

Sets hostname as defined in the +config+ partition.

== Upgrade data store

Service: +upgrade-shared-data-store.service+, script +/opt/ic/bin/upgrade-shared-data-store.sh+.
Depends on mount of requisite filesystem.

This script is intended as a hook to perform any required conversion of the
contents of +/var/lib/ic/data+. Such may be necessary as a one-time change
after upgrade from one system image to another.

== nftables reload on change

Service: +reload_nftables.service+ depending +reload_nftables.path+

This lets systemd monitor the contents of the +nftables.conf+ ruleset file
(dynamically generated by IC stack depending on registry) and issues a reload
command to the nftables subsystem in order to activate the ruleset.

== Start node_exporter

Service: +node_exporter.service+. Depends on +setup-node_exporter-keys.service+.

Starts the +node_exporter+ service to make machine metrics accessible externally.

== Generate IC config

Service: generate-ic-config.service creates a config file from ic.json.template, which is used by the replica and other ic services

== Start IC replica

Starts the nodemaneger which in turn monitors and starts the IC replica service.
