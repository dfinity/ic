syntax = "proto3";
package state.queues.v1;

import "state/ingress/v1/ingress.proto";
import "types/v1/types.proto";

message Cycles {
  reserved 1;
  reserved "raw"; // Originally was defined as a uint64
  bytes raw_cycles = 2;
}

message Funds {
  reserved 1;
  reserved "cycles";
  uint64 icp = 2;
  Cycles cycles_struct = 3;
}

message StreamFlags {
  bool deprecated_responses_only = 1;
}

message Stream {
  uint64 messages_begin = 1;
  repeated RequestOrResponse messages = 2;
  reserved 3, 4;
  reserved "signals_begin", "signals";
  uint64 signals_end = 5;
  repeated uint64 reject_signals = 6;
  StreamFlags reverse_stream_flags = 7;
}

message StreamEntry {
  types.v1.SubnetId subnet_id = 1;
  Stream subnet_stream = 2;
}

message RequestMetadata {
  optional uint64 call_tree_depth = 1;
  optional uint64 call_tree_start_time_nanos = 2;
  // A point in the future vs. `call_tree_start_time` at which a request would ideally have concluded
  // its lifecycle on the IC. Unlike `call_tree_depth` and `call_tree_start_time`, the deadline
  // does not have to be a constant for the whole call tree. Rather it's valid only for the subtree of
  // downstream calls at any point in the tree, i.e. it is allowed and desirable for a subtree to have
  // a tighter deadline than the tree as whole.
  //
  // Reserved for future use (guaranteed replies won't be affected).
  optional uint64 call_subtree_deadline_nanos = 3;
}

message Request {
  types.v1.CanisterId receiver = 1;
  types.v1.CanisterId sender = 2;
  uint64 sender_reply_callback = 3;
  Funds payment = 4;
  string method_name = 5;
  bytes method_payload = 6;
  Cycles cycles_payment = 7;
  RequestMetadata metadata = 8;
  // If non-zero, this is a best-effort call.
  uint32 deadline_seconds = 9;
}

message RejectContext {
  uint64 reject_code = 1;
  string reject_message = 2;
}

message Response {
  types.v1.CanisterId originator = 1;
  types.v1.CanisterId respondent = 2;
  uint64 originator_reply_callback = 3;
  Funds refund = 4;
  oneof response_payload {
    bytes data = 5;
    RejectContext reject = 6;
  }
  Cycles cycles_refund = 7;
  // If non-zero, this is a best-effort call.
  uint32 deadline_seconds = 8;
}

message RequestOrResponse {
  oneof r {
    Request request = 1;
    Response response = 2;
  }
}

message MessageDeadline {
  uint64 deadline = 1;
  uint64 index = 2;
}

message InputOutputQueue {
  repeated RequestOrResponse queue = 1;
  uint64 begin = 2;
  uint64 capacity = 3;
  uint64 num_slots_reserved = 4;
  // Ordered ranges of messages having the same request deadline. Each range
  // is represented as a deadline and its end index (the `QueueIndex` just
  // past the last request where the deadline applies). Both the deadlines and
  // queue indices are strictly increasing.
  repeated MessageDeadline deadline_range_ends = 5;
  // Queue index from which request timing out will resume.
  uint64 timeout_index = 6;
}

message QueueEntry {
  types.v1.CanisterId canister_id = 1;
  InputOutputQueue queue = 2;
}

message CanisterQueues {
  reserved 1; // this is from canisterId
  reserved "canister_id";
  repeated ingress.v1.Ingress ingress_queue = 2;
  repeated QueueEntry input_queues = 3;
  // Upgrade: input_schedule is mapped to local_subnet_input_schedule.
  repeated types.v1.CanisterId input_schedule = 4;
  repeated QueueEntry output_queues = 5;
  enum NextInputQueue {
    NEXT_INPUT_QUEUE_UNSPECIFIED = 0;
    NEXT_INPUT_QUEUE_LOCAL_SUBNET = 1;
    NEXT_INPUT_QUEUE_INGRESS = 2;
    NEXT_INPUT_QUEUE_REMOTE_SUBNET = 3;
  }
  NextInputQueue next_input_queue = 6;
  // Downgrade: both queues are mapped back to input_schedule in the current
  // release.
  repeated types.v1.CanisterId local_subnet_input_schedule = 7;
  repeated types.v1.CanisterId remote_subnet_input_schedule = 8;
}
