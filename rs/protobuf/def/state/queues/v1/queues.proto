syntax = "proto3";
package state.queues.v1;

import "state/ingress/v1/ingress.proto";
import "types/v1/errors.proto";
import "types/v1/types.proto";

message Cycles {
  reserved 1;
  reserved "raw"; // Originally was defined as a uint64
  bytes raw_cycles = 2;
}

message Funds {
  reserved 1;
  reserved "cycles";
  uint64 icp = 2;
  Cycles cycles_struct = 3;
}

enum RejectReason {
  REJECT_REASON_UNSPECIFIED = 0;
  REJECT_REASON_CANISTER_MIGRATING = 1;
}

message RejectSignal {
  RejectReason reason = 1;
  uint64 index = 2;
}

message StreamFlags {
  bool deprecated_responses_only = 1;
}

message Stream {
  uint64 messages_begin = 1;
  repeated RequestOrResponse messages = 2;
  reserved 3, 4;
  reserved "signals_begin", "signals";
  uint64 signals_end = 5;
  // TODO: MR-577 Remove `deprecated_reject_signals` once all replicas are updated.
  repeated uint64 deprecated_reject_signals = 6;
  repeated RejectSignal reject_signals = 8;
  StreamFlags reverse_stream_flags = 7;
}

message StreamEntry {
  types.v1.SubnetId subnet_id = 1;
  Stream subnet_stream = 2;
}

message RequestMetadata {
  optional uint64 call_tree_depth = 1;
  optional uint64 call_tree_start_time_nanos = 2;
  // A point in the future vs. `call_tree_start_time` at which a request would ideally have concluded
  // its lifecycle on the IC. Unlike `call_tree_depth` and `call_tree_start_time`, the deadline
  // does not have to be a constant for the whole call tree. Rather it's valid only for the subtree of
  // downstream calls at any point in the tree, i.e. it is allowed and desirable for a subtree to have
  // a tighter deadline than the tree as whole.
  //
  // Reserved for future use (guaranteed replies won't be affected).
  optional uint64 call_subtree_deadline_nanos = 3;
}

message Request {
  types.v1.CanisterId receiver = 1;
  types.v1.CanisterId sender = 2;
  uint64 sender_reply_callback = 3;
  Funds payment = 4;
  string method_name = 5;
  bytes method_payload = 6;
  Cycles cycles_payment = 7;
  RequestMetadata metadata = 8;
  // If non-zero, this is a best-effort call.
  uint32 deadline_seconds = 9;
}

message RejectContext {
  reserved 1;
  reserved "reject_code_old";
  types.v1.RejectCode reject_code = 3;
  string reject_message = 2;
}

message Response {
  types.v1.CanisterId originator = 1;
  types.v1.CanisterId respondent = 2;
  uint64 originator_reply_callback = 3;
  Funds refund = 4;
  oneof response_payload {
    bytes data = 5;
    RejectContext reject = 6;
  }
  Cycles cycles_refund = 7;
  // If non-zero, this is a best-effort call.
  uint32 deadline_seconds = 8;
}

message RequestOrResponse {
  oneof r {
    Request request = 1;
    Response response = 2;
  }
}

message MessageDeadline {
  uint64 deadline = 1;
  uint64 index = 2;
}

message InputOutputQueue {
  repeated RequestOrResponse queue = 1;
  uint64 begin = 2;
  uint64 capacity = 3;
  uint64 num_slots_reserved = 4;
  // Ordered ranges of messages having the same request deadline. Each range
  // is represented as a deadline and its end index (the `QueueIndex` just
  // past the last request where the deadline applies). Both the deadlines and
  // queue indices are strictly increasing.
  repeated MessageDeadline deadline_range_ends = 5;
  // Queue index from which request timing out will resume.
  uint64 timeout_index = 6;
}

message QueueEntry {
  types.v1.CanisterId canister_id = 1;
  InputOutputQueue queue = 2;
}

// A pool holding all of a canister's incoming and outgoing canister messages.
message MessagePool {
  // A pool entry: a message keyed by its ID.
  message Entry {
    uint64 id = 1;
    RequestOrResponse message = 2;
  }
  // A message deadline.
  //
  // Recorded explicitly for outbound guaranteed response requests only.
  // Best-effort messages have explicit deadlines.
  message MessageDeadline {
    uint64 id = 1;
    uint32 deadline_seconds = 2;
  }

  // Map of messages by message ID.
  repeated Entry messages = 1;
  // The (implicit) deadlines of all outbound guaranteed response requests (only).
  repeated MessageDeadline outbound_guaranteed_request_deadlines = 2;
  // Strictly monotonically increasing counter used to generate unique message
  // IDs.
  uint64 message_id_generator = 3;
}

message CanisterQueue {
  message QueueItem {
    oneof r {
      // A reference into the message pool (a pool assigned ID).
      uint64 reference = 1;

      // A marker for a transient reject response for the given callback ID.
      // uint64 transient_reject_for_callback_id = 2;
      // A marker for an unknown reject response for the given callback ID.
      // uint64 unknown_reject_for_callback_id = 3;
    }
  }

  // FIFO queue of references into the pool and reject response markers.
  repeated QueueItem queue = 1;
  // Maximum number of requests or responses that can be enqueued at any one time.
  uint64 capacity = 2;
  // Number of slots used by or reserved for responses.
  uint64 response_slots = 3;
}

message CanisterQueues {
  reserved 1, 4;
  reserved "canister_id", "input_schedule";

  repeated ingress.v1.Ingress ingress_queue = 2;

  repeated QueueEntry input_queues = 3;
  repeated QueueEntry output_queues = 5;

  // Input queue from and output queue to `canister_id`.
  message CanisterQueuePair {
    types.v1.CanisterId canister_id = 1;
    CanisterQueue input_queue = 2;
    CanisterQueue output_queue = 3;
  }
  repeated CanisterQueuePair canister_queues = 9;
  MessagePool pool = 10;

  enum NextInputQueue {
    NEXT_INPUT_QUEUE_UNSPECIFIED = 0;
    NEXT_INPUT_QUEUE_LOCAL_SUBNET = 1;
    NEXT_INPUT_QUEUE_INGRESS = 2;
    NEXT_INPUT_QUEUE_REMOTE_SUBNET = 3;
  }
  NextInputQueue next_input_queue = 6;

  repeated types.v1.CanisterId local_subnet_input_schedule = 7;
  repeated types.v1.CanisterId remote_subnet_input_schedule = 8;

  uint64 guaranteed_response_memory_reservations = 11;
}
